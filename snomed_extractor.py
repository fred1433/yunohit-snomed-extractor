import google.generativeai as genai
import json
import re
from typing import Dict, Any
from config import Config
from models import MedicalNote, SNOMEDExtraction, ClinicalFinding, Procedure, BodyStructure
from api_security import security_manager
import asyncio
import time
from snomed_validator import SNOMEDValidator

class SNOMEDExtractor:
    """Extracteur d'informations SNOMED CT √† partir de notes m√©dicales"""
    
    def __init__(self):
        """Initialiser l'extracteur avec le mod√®le Gemini"""
        Config.validate()
        genai.configure(api_key=Config.GOOGLE_API_KEY)
        # Mod√®le configurable
        self.model_name = Config.GEMINI_MODEL
        self.model = genai.GenerativeModel(self.model_name)
    
    def set_model(self, model_name: str):
        """Changer le mod√®le utilis√©"""
        self.model_name = model_name
        self.model = genai.GenerativeModel(self.model_name)
        print(f"üîÑ Mod√®le chang√© vers : {model_name}")
    
    def create_extraction_prompt(self, medical_note: str) -> str:
        """Cr√©er un prompt √©ducatif optimis√© pour extraction compl√®te"""
        prompt = f"""Dans un contexte √©ducatif de classification m√©dicale, analyse ce cas d'√©tude :

{medical_note}

Extrais UNIQUEMENT les termes appartenant aux 3 hi√©rarchies SNOMED CT cibl√©es :

1. **CLINICAL FINDING** (Constatations cliniques) :
   - Sympt√¥mes observ√©s (ex: √©ruption cutan√©e, prurit)
   - Signes cliniques (ex: l√©sions v√©siculeuses)
   - Diagnostics √©tablis (ex: varicelle)
   - √âtats pathologiques

2. **PROCEDURE** (Interventions/Proc√©dures) :
   - Traitements administr√©s (ex: antihistaminique oral)
   - Soins m√©dicaux (ex: soins locaux)
   - Recommandations th√©rapeutiques (ex: √©viction scolaire)
   - Actes m√©dicaux

3. **BODY STRUCTURE** (Structures corporelles) :
   - Parties anatomiques mentionn√©es (ex: membres, tronc)
   - Organes, r√©gions corporelles
   - Structures anatomiques

**EXCLURE** : ant√©c√©dents, contexte familial, informations administratives, expositions

Format JSON requis :
{{
  "termes_medicaux": [
    {{
      "terme": "terme m√©dical exact",
      "categorie": "clinical_finding/procedure/body_structure",
      "code_classification": "code SNOMED CT num√©rique unique pour ce terme",
      "negation": "positive/negative",
      "famille": "patient/family", 
      "suspicion": "confirmed/suspected",
      "antecedent": "current/history"
    }}
  ]
}}

IMPORTANT : Assigne un code SNOMED CT diff√©rent et appropri√© pour chaque terme m√©dical.
Exemples de codes : 
- Varicelle: 38907003
- √âruption cutan√©e: 271807003  
- Antihistaminique: 432102000
- Membres: 445662006

R√àGLES pour les modifieurs :
- n√©gation : "positive" si pr√©sent, "negative" si absent/ni√©
- famille : "patient" pour le patient, "family" pour ant√©c√©dent familial
- suspicion : "confirmed" si certain, "suspected" si suspect√©
- antecedent : "current" si actuel, "history" si ant√©c√©dent m√©dical

Retourne uniquement le JSON avec les termes des 3 hi√©rarchies cibl√©es."""
        return prompt
    
    def extract_snomed_info(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """Extraction optimis√©e ONE-SHOT avec codes SNOMED CT et modifieurs contextuels"""
        try:
            # üõ°Ô∏è S√âCURIT√â : V√©rifier les limites avant l'appel API
            can_proceed, message = security_manager.can_make_request()
            if not can_proceed:
                print(f"üö´ EXTRACTION BLOQU√âE : {message}")
                print("‚è∞ R√©essayez plus tard ou contactez l'administrateur")
                return self._create_empty_extraction(medical_note)
            
            print(f"üîí S√©curit√© : {message}")
            print("üîç Extraction ONE-SHOT avec modifieurs contextuels...")
            
            prompt = self.create_extraction_prompt(medical_note.content)
            
            response = self.model.generate_content(prompt)
            
            # üõ°Ô∏è S√âCURIT√â : Enregistrer l'appel API r√©ussi
            security_manager.record_api_call(estimated_cost=0.015)  # Co√ªt estim√© pour Gemini Flash
            security_manager.print_usage_warning()
            
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                
                if hasattr(candidate, 'finish_reason') and candidate.finish_reason == 2:
                    print("‚ùå Extraction bloqu√©e par filtres de s√©curit√©")
                    return self._create_empty_extraction(medical_note)
                
                if hasattr(response, 'text') and response.text:
                    response_text = response.text
                elif hasattr(candidate.content, 'parts') and candidate.content.parts:
                    response_text = "".join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
                else:
                    print("‚ùå Pas de texte dans la r√©ponse")
                    return self._create_empty_extraction(medical_note)
            else:
                print("‚ùå Pas de candidat dans la r√©ponse")
                return self._create_empty_extraction(medical_note)
            
            print("‚úÖ R√©ponse re√ßue, parsing...")
            
            # Parser la r√©ponse simple
            parsed_data = self.parse_gemini_response(response_text)
            
            # Convertir le format en objets SNOMED CT
            clinical_findings = []
            procedures = []
            body_structures = []
            
            # Traiter les termes m√©dicaux avec codes et modifieurs fournis par Gemini
            for terme_data in parsed_data.get("termes_medicaux", []):
                terme = terme_data.get("terme", "")
                categorie = terme_data.get("categorie", "").lower()
                code_snomed = terme_data.get("code_classification", "UNKNOWN")
                
                # Extraire les modifieurs contextuels
                negation = terme_data.get("negation", "positive")
                family = terme_data.get("famille", "patient")  # Note: "famille" en fran√ßais dans le JSON
                suspicion = terme_data.get("suspicion", "confirmed")
                antecedent = terme_data.get("antecedent", "current")
                
                if "symptome" in categorie or "diagnostic" in categorie or "finding" in categorie or "clinical_finding" in categorie:
                    clinical_findings.append(ClinicalFinding(
                        term=terme,
                        description=f"Constatation clinique : {terme}",
                        context=f"Extrait de la note m√©dicale",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "traitement" in categorie or "procedure" in categorie or "intervention" in categorie:
                    procedures.append(Procedure(
                        term=terme,
                        description=f"Intervention/Proc√©dure : {terme}",
                        context=f"Extrait de la note m√©dicale",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "anatomie" in categorie or "structure" in categorie or "corps" in categorie or "body_structure" in categorie:
                    body_structures.append(BodyStructure(
                        term=terme,
                        description=f"Structure corporelle : {terme}",
                        context=f"Extrait de la note m√©dicale",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                else:
                    # Ignorer les termes qui ne correspondent √† aucune des 3 hi√©rarchies cibl√©es
                    print(f"‚ö†Ô∏è  Terme ignor√© (hors hi√©rarchies cibl√©es) : {terme} ({categorie})")
                    continue
            
            print(f"‚úÖ Extraction r√©ussie : {len(clinical_findings)} constatations, {len(procedures)} proc√©dures, {len(body_structures)} structures")
            return SNOMEDExtraction(
                original_note=medical_note,
                clinical_findings=clinical_findings,
                procedures=procedures,
                body_structures=body_structures
            )
            
        except Exception as e:
            print(f"‚ùå Erreur extraction : {e}")
            return self._create_empty_extraction(medical_note)
    
    def parse_gemini_response(self, response_text: str) -> Dict[str, Any]:
        """Parser la r√©ponse JSON de Gemini"""
        try:
            # Nettoyer la r√©ponse pour extraire le JSON
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            else:
                print("‚ùå Aucun JSON trouv√© dans la r√©ponse")
                return {"termes_medicaux": []}
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur parsing JSON : {e}")
            print(f"R√©ponse re√ßue : {response_text[:500]}...")
            return {"termes_medicaux": []}
    
    def _extract_response_text(self, response) -> str:
        """Extraire le texte d'une r√©ponse Gemini"""
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason == 2:
                print("‚ùå R√©ponse bloqu√©e par filtres de s√©curit√©")
                return ""
            
            if hasattr(response, 'text') and response.text:
                return response.text
            elif hasattr(candidate.content, 'parts') and candidate.content.parts:
                return "".join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
        
        print("‚ùå Pas de texte dans la r√©ponse")
        return ""
    
    def _create_empty_extraction(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """Cr√©er une extraction vide en cas d'erreur"""
        return SNOMEDExtraction(
            original_note=medical_note,
            clinical_findings=[],
            procedures=[],
            body_structures=[]
        ) 
    
    def extract_triple_parallel(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """Extraction avec 3 appels parall√®les pour am√©liorer la robustesse"""
        try:
            # üõ°Ô∏è S√âCURIT√â : V√©rifier les limites avant les appels API
            can_proceed, message = security_manager.can_make_request()
            if not can_proceed:
                print(f"üö´ EXTRACTION BLOQU√âE : {message}")
                return self._create_empty_extraction(medical_note)
            
            print(f"üîí S√©curit√© : {message}")
            print("üîç Extraction TRIPLE PARALL√àLE commenc√©e...")
            
            prompt = self.create_extraction_prompt(medical_note.content)
            
            # Faire 3 appels parall√®les avec le m√™me prompt
            print("üìã Lancement de 3 appels parall√®les √† Gemini...")
            
            responses = []
            for i in range(3):
                print(f"üîÑ Appel {i+1}/3...")
                response = self.model.generate_content(prompt)
                security_manager.record_api_call(estimated_cost=0.02)
                responses.append(response)
            
            print("‚úÖ 3 appels termin√©s, analyse des r√©ponses...")
            
            # Collecter tous les termes de tous les appels
            all_terms = []
            
            for i, response in enumerate(responses):
                print(f"üìä Analyse r√©ponse {i+1}/3...")
                response_text = self._extract_response_text(response)
                if response_text:
                    parsed_data = self.parse_gemini_response(response_text)
                    terms = parsed_data.get("termes_medicaux", [])
                    print(f"   ‚Üí {len(terms)} termes extraits")
                    all_terms.extend(terms)
                else:
                    print(f"   ‚Üí √âchec de l'extraction")
            
            print(f"üîÑ Total combin√© : {len(all_terms)} termes")
            
            # D√©dupliquer par terme (garder le premier trouv√©)
            seen_terms = set()
            unique_terms = []
            for term_data in all_terms:
                terme = term_data.get("terme", "").lower().strip()
                if terme and terme not in seen_terms:
                    seen_terms.add(terme)
                    unique_terms.append(term_data)
            
            print(f"‚úÖ Apr√®s d√©duplication : {len(unique_terms)} termes uniques")
            
            # Convertir en objets SNOMED CT
            clinical_findings = []
            procedures = []
            body_structures = []
            
            for terme_data in unique_terms:
                terme = terme_data.get("terme", "")
                categorie = terme_data.get("categorie", "").lower()
                code_snomed = terme_data.get("code_classification", "UNKNOWN")
                
                # Extraire les modifieurs contextuels
                negation = terme_data.get("negation", "positive")
                family = terme_data.get("famille", "patient")
                suspicion = terme_data.get("suspicion", "confirmed")
                antecedent = terme_data.get("antecedent", "current")
                
                if "symptome" in categorie or "diagnostic" in categorie or "finding" in categorie or "clinical_finding" in categorie:
                    clinical_findings.append(ClinicalFinding(
                        term=terme,
                        description=f"Constatation clinique : {terme}",
                        context="Extrait par m√©thode triple parall√®le",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "traitement" in categorie or "procedure" in categorie or "intervention" in categorie:
                    procedures.append(Procedure(
                        term=terme,
                        description=f"Intervention/Proc√©dure : {terme}",
                        context="Extrait par m√©thode triple parall√®le",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "structure" in categorie or "body_structure" in categorie:
                    body_structures.append(BodyStructure(
                        term=terme,
                        description=f"Structure corporelle : {terme}",
                        context="Extrait par m√©thode triple parall√®le",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
            
            print(f"‚úÖ Extraction TRIPLE PARALL√àLE r√©ussie : {len(clinical_findings)} constatations, {len(procedures)} proc√©dures, {len(body_structures)} structures")
            security_manager.print_usage_warning()
            
            return SNOMEDExtraction(
                original_note=medical_note,
                clinical_findings=clinical_findings,
                procedures=procedures,
                body_structures=body_structures
            )
            
        except Exception as e:
            print(f"‚ùå Erreur extraction triple parall√®le : {e}")
            return self._create_empty_extraction(medical_note)
    
    def extract_triple_with_validation_fusion(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """
        M√âTHODE ULTIME : 3 extractions + validation + fusion de TOUS les r√©sultats valid√©s
        Collecte et combine tous les termes valid√©s des 3 extractions pour maximiser le r√©sultat
        """
        try:
            # üõ°Ô∏è S√âCURIT√â : V√©rifier les limites avant les appels API
            can_proceed, message = security_manager.can_make_request()
            if not can_proceed:
                print(f"üö´ EXTRACTION BLOQU√âE : {message}")
                return self._create_empty_extraction(medical_note)
            
            print(f"üîí S√©curit√© : {message}")
            print("üéØ EXTRACTION TRIPLE + VALIDATION + FUSION commenc√©e...")
            
            # Charger le validateur une seule fois pour toutes les validations
            validator = SNOMEDValidator()
            print("‚úÖ Validateur SNOMED CT charg√©")
            
            # Lancer 3 extractions s√©quentielles avec validation imm√©diate
            all_valid_items = []
            extraction_stats = []
            
            for i in range(3):
                print(f"\nüîÑ === EXTRACTION {i+1}/3 ===")
                
                # Extraction avec Gemini
                extraction = self.extract_snomed_info(medical_note)
                security_manager.record_api_call(estimated_cost=0.02)
                
                # Collecter tous les items extraits
                all_items = (extraction.clinical_findings + 
                           extraction.procedures + 
                           extraction.body_structures)
                
                print(f"üìä Extraction {i+1} : {len(all_items)} termes extraits")
                
                # Validation imm√©diate des termes de cette extraction
                valid_items_this_round = []
                for item in all_items:
                    if validator.validate_code(item.snomed_code):
                        valid_items_this_round.append(item)
                
                print(f"‚úÖ Validation {i+1} : {len(valid_items_this_round)}/{len(all_items)} termes valid√©s")
                
                # Ajouter √† la collection globale
                all_valid_items.extend(valid_items_this_round)
                
                extraction_stats.append({
                    'total': len(all_items),
                    'valid': len(valid_items_this_round),
                    'rate': (len(valid_items_this_round) / len(all_items) * 100) if len(all_items) > 0 else 0
                })
            
            print(f"\nüîÑ Total avant d√©duplication : {len(all_valid_items)} termes valid√©s")
            
            # D√âDUPLICATION par code SNOMED (pas par terme)
            seen_codes = set()
            unique_valid_items = []
            
            for item in all_valid_items:
                code = item.snomed_code
                if code and code not in seen_codes:
                    seen_codes.add(code)
                    unique_valid_items.append(item)
                    print(f"   ‚ûï {item.term} ({code})")
                else:
                    print(f"   üîÑ Doublon ignor√© : {item.term} ({code})")
            
            print(f"‚ú® Apr√®s d√©duplication : {len(unique_valid_items)} termes uniques valid√©s")
            
            # R√©organiser par type pour cr√©er l'objet final
            final_clinical_findings = []
            final_procedures = []
            final_body_structures = []
            
            for item in unique_valid_items:
                if hasattr(item, '__class__'):
                    class_name = item.__class__.__name__
                    if class_name == 'ClinicalFinding':
                        final_clinical_findings.append(item)
                    elif class_name == 'Procedure':
                        final_procedures.append(item)
                    elif class_name == 'BodyStructure':
                        final_body_structures.append(item)
            
            # Statistiques finales
            print(f"\nüéØ R√âSULTAT FINAL DE LA FUSION :")
            print(f"   üîç {len(final_clinical_findings)} constatations cliniques")
            print(f"   ‚öïÔ∏è  {len(final_procedures)} proc√©dures/traitements")
            print(f"   ü´Ä {len(final_body_structures)} structures corporelles")
            print(f"   üìä TOTAL : {len(unique_valid_items)} entit√©s valid√©es")
            
            # Afficher les statistiques par extraction
            print(f"\nüìà STATISTIQUES PAR EXTRACTION :")
            for i, stats in enumerate(extraction_stats, 1):
                print(f"   Extraction {i} : {stats['valid']}/{stats['total']} ({stats['rate']:.1f}%)")
            
            # Calculer le gain vs m√©thode simple
            total_extractions = sum(stats['total'] for stats in extraction_stats)
            total_valid_before_fusion = sum(stats['valid'] for stats in extraction_stats)
            gain = len(unique_valid_items) - max(stats['valid'] for stats in extraction_stats)
            
            print(f"\nüöÄ PERFORMANCE DE LA FUSION :")
            print(f"   üìä Avant fusion : max {max(stats['valid'] for stats in extraction_stats)} entit√©s valid√©es")
            print(f"   ‚ú® Apr√®s fusion : {len(unique_valid_items)} entit√©s uniques")
            print(f"   üìà GAIN : +{gain} entit√©s suppl√©mentaires !")
            
            security_manager.print_usage_warning()
            
            return SNOMEDExtraction(
                original_note=medical_note,
                clinical_findings=final_clinical_findings,
                procedures=final_procedures,
                body_structures=final_body_structures
            )
            
        except Exception as e:
            print(f"‚ùå Erreur extraction triple + fusion : {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_extraction(medical_note)
    
    async def extract_triple_with_validation_fusion_v2(self, text, use_context_modifiers=True):
        """
        M√âTHODE ULTIME V2 : Triple extraction parall√®le + validation SNOMED + validation s√©mantique finale
        
        Processus optimis√© :
        1. 3 extractions Gemini Pro EN PARALL√àLE (chronom√©tr√©es)
        2. Validation SNOMED de chaque extraction (chronom√©tr√©e)  
        3. Fusion + d√©duplication par code SNOMED (chronom√©tr√©e)
        4. Validation s√©mantique hybride SUR LE TABLEAU FINAL SEULEMENT (chronom√©tr√©e)
        
        Returns:
            dict: R√©sultats finaux avec statistiques d√©taill√©es et temps
        """
        print("üéØ EXTRACTION ULTIME V2 : Triple extraction parall√®le + validation SNOMED + validation s√©mantique finale")
        start_time = time.time()
        
        # V√©rifications pr√©liminaires
        if not self._security_check():
            return {"error": "Limites de s√©curit√© d√©pass√©es"}
        
        # Initialiser le validator SNOMED
        if not hasattr(self, 'validator') or self.validator is None:
            print("‚úÖ Validateur SNOMED CT charg√©")
            self.validator = SNOMEDValidator()
        
        # === PHASE 1 : TRIPLE EXTRACTION PARALL√àLE ===
        parallel_start = time.time()
        print("üöÄ D√©but des 3 extractions en parall√®le...")
        
        async def extract_single(extraction_num):
            """Extraction individuelle avec chronom√©trage"""
            extraction_start = time.time()
            print(f"üîÑ === EXTRACTION {extraction_num}/3 ===")
            
            # CORRECTION : Utiliser asyncio.to_thread pour vraie parall√©lisation
            entities = await asyncio.to_thread(
                self.extract_medical_entities, 
                text, 
                use_context_modifiers
            )
            
            extraction_time = time.time() - extraction_start
            print(f"‚úÖ Extraction {extraction_num} termin√©e en ‚è±Ô∏è {extraction_time:.2f}s")
            return entities, extraction_time
        
        # Ex√©cution des 3 extractions en parall√®le  
        results = await asyncio.gather(
            extract_single(1),
            extract_single(2), 
            extract_single(3)
        )
        
        parallel_time = time.time() - parallel_start
        individual_times = [result[1] for result in results]
        print(f"üéØ 3 extractions parall√®les termin√©es en ‚è±Ô∏è {parallel_time:.2f}s (vs {sum(individual_times):.2f}s s√©quentiel = Gain: {sum(individual_times) - parallel_time:.2f}s)")
        
        # === PHASE 2 : VALIDATION SNOMED AVEC CHRONOM√âTRAGE ===
        validation_phase_start = time.time()
        print(f"\nüîç === VALIDATION SNOMED (3 extractions) ===")
        
        all_validated_terms = []
        extraction_stats = []
        
        for i, (entities_result, _) in enumerate(results):
            extraction_num = i + 1
            all_terms = []
            
            # Correction : acc√®s correct √† la structure des donn√©es
            if entities_result and 'entities' in entities_result:
                entities = entities_result['entities']
                
                # Collecte des termes avec structure corrig√©e ET modifieurs contextuels
                for finding in entities.get('findings', []):
                    all_terms.append({
                        'term': finding['term'],
                        'snomed_code': finding.get('snomed_code', 'UNKNOWN'),
                        'category': finding.get('category', 'clinical_finding'),
                        'negation': finding.get('negation', 'positive'),
                        'family': finding.get('family', 'patient'),
                        'suspicion': finding.get('suspicion', 'confirmed'),
                        'antecedent': finding.get('antecedent', 'current')
                    })
                for procedure in entities.get('procedures', []):
                    all_terms.append({
                        'term': procedure['term'],
                        'snomed_code': procedure.get('snomed_code', 'UNKNOWN'),
                        'category': procedure.get('category', 'procedure'),
                        'negation': procedure.get('negation', 'positive'),
                        'family': procedure.get('family', 'patient'),
                        'suspicion': procedure.get('suspicion', 'confirmed'),
                        'antecedent': procedure.get('antecedent', 'current')
                    })
                for structure in entities.get('body_structures', []):
                    all_terms.append({
                        'term': structure['term'],
                        'snomed_code': structure.get('snomed_code', 'UNKNOWN'),
                        'category': structure.get('category', 'body_structure'),
                        'negation': structure.get('negation', 'positive'),
                        'family': structure.get('family', 'patient'),
                        'suspicion': structure.get('suspicion', 'confirmed'),
                        'antecedent': structure.get('antecedent', 'current')
                    })
                
                print(f"üìä Extraction {extraction_num} : {len(all_terms)} termes extraits")
            else:
                print(f"‚ùå Extraction {extraction_num} : pas de donn√©es")
                continue
            
            # Validation SNOMED avec chronom√©trage ET pr√©servation des modifieurs
            validation_start = time.time()
            validated = []
            valid_count = 0
            
            for term_data in all_terms:
                term = term_data['term']
                
                # üéØ NOUVELLE LOGIQUE PRIORITAIRE
                snomed_code = None
                snomed_term = None
                
                # ü•á PRIORIT√â 1 : Recherche EXACTE du terme dans la base SNOMED
                exact_code = self.validator.find_exact_term_code(term)
                if exact_code:
                    snomed_code = exact_code
                    snomed_term = term 
                    print(f"   üéØ Terme EXACT trouv√© : {term} ‚Üí {exact_code} (UTILISE LE TERME EXACT : '{snomed_term}')")
                else:
                    # ü•à PRIORIT√â 2 : V√©rifier si le code de Gemini existe dans notre base
                    gemini_code = term_data.get('snomed_code', 'UNKNOWN')
                    if gemini_code != 'UNKNOWN' and self.validator.validate_code(gemini_code):
                        snomed_code = gemini_code
                        snomed_term = self.validator.get_french_term(gemini_code)
                        print(f"   ‚úÖ Code Gemini valid√© : {term} ‚Üí {gemini_code} ('{snomed_term}')")
                    else:
                        # ü•â PRIORIT√â 3 : Fallback - chercher nous-m√™mes
                        snomed_code = self.validator.find_closest_code(term)
                        if snomed_code:
                            snomed_term = self.validator.get_french_term(snomed_code)
                            print(f"   üîç Code trouv√© par recherche : {term} ‚Üí {snomed_code}")
                        else:
                            print(f"   ‚ùå Aucun code valide trouv√© pour : {term} (Gemini: {gemini_code})")
                            continue
                
                if snomed_code and snomed_term:
                    validated.append({
                        'term': term,
                        'snomed_code': snomed_code,
                        'snomed_term': snomed_term,
                        'valid': True,
                        # Pr√©server les modifieurs contextuels
                        'negation': term_data.get('negation', 'positive'),
                        'family': term_data.get('family', 'patient'),
                        'suspicion': term_data.get('suspicion', 'confirmed'),
                        'antecedent': term_data.get('antecedent', 'current'),
                        'category': term_data.get('category', 'clinical_finding')
                    })
                    valid_count += 1
                else:
                    print(f"   ‚ùå Aucun code valide trouv√© pour : {term} (Gemini: {gemini_code})")
            
            validation_time = time.time() - validation_start
            print(f"‚úÖ Validation SNOMED {extraction_num} : {valid_count}/{len(all_terms)} termes valid√©s (‚è±Ô∏è {validation_time:.2f}s)")
            
            # Collecte des termes valid√©s
            for term_data in validated:
                if term_data['valid']:
                    all_validated_terms.append(term_data)
            
            extraction_stats.append((extraction_num, valid_count, len(all_terms)))
        
        # === PHASE 3 : FUSION ET D√âDUPLICATION ===
        fusion_start = time.time()
        print(f"\nüîÑ === FUSION ET D√âDUPLICATION ===")
        print(f"Total avant d√©duplication : {len(all_validated_terms)} termes valid√©s SNOMED")
        
        unique_terms = {}
        for term_data in all_validated_terms:
            code = term_data['snomed_code']
            if code not in unique_terms:
                print(f"   ‚ûï {term_data['term']} ({code})")
                unique_terms[code] = term_data
            else:
                print(f"   üîÑ Doublon ignor√© : {term_data['term']} ({code})")
        
        fusion_time = time.time() - fusion_start
        print(f"‚ú® Apr√®s d√©duplication : {len(unique_terms)} termes uniques valid√©s SNOMED (‚è±Ô∏è {fusion_time:.2f}s)")
        
        # === PHASE 4 : VALIDATION S√âMANTIQUE SUR LE TABLEAU FINAL ===
        semantic_start = time.time()
        print(f"\nüß† === VALIDATION S√âMANTIQUE HYBRIDE ===")
        
        # Pr√©paration des paires pour validation s√©mantique
        semantic_pairs = []
        for term_data in unique_terms.values():
            original_term = term_data['term']
            snomed_term = term_data['snomed_term']
            if original_term.lower() != snomed_term.lower():
                semantic_pairs.append((original_term, snomed_term))
        
        if not semantic_pairs:
            print("üìä Aucune validation s√©mantique n√©cessaire : tous les termes sont identiques")
            final_validated = []
            for term_data in unique_terms.values():
                entity = {
                    'term': term_data['term'],
                    'snomed_code': term_data['snomed_code'],
                    'snomed_term': term_data['snomed_term'],
                    'category': self._categorize_by_snomed_code(term_data['snomed_code']),
                    'negation': term_data.get('negation', 'positive'),
                    'family': term_data.get('family', 'patient'),
                    'suspicion': term_data.get('suspicion', 'confirmed'),
                    'antecedent': term_data.get('antecedent', 'current')
                }
                final_validated.append(entity)
        else:
            print(f"üîç Validation s√©mantique hybride : {len(semantic_pairs)} paires √† analyser")
            
            # Validation s√©mantique hybride
            semantic_results = await self._validate_semantic_coherence_batch(semantic_pairs)
            
            # Application des r√©sultats de validation s√©mantique
            if semantic_pairs:
                print(f"üìä Validation termin√©e : {len([r for r in semantic_results.values() if r['valid']])}/{len(semantic_pairs)} valid√©es")
                
                # Cr√©er un dictionnaire pour associer les paires √† leurs r√©sultats
                validation_results = {}
                for i, (original_term, snomed_term) in enumerate(semantic_pairs):
                    if i in semantic_results:
                        validation_results[(original_term.lower(), snomed_term.lower())] = semantic_results[i]
                
                # Application des r√©sultats
                final_validated = []
                rejected_terms = []
                
                for term_data in unique_terms.values():
                    original_term = term_data['term']
                    snomed_term = term_data['snomed_term']
                    pair_key = (original_term.lower(), snomed_term.lower())
                    
                    # V√©rifier si cette paire a √©t√© valid√©e s√©mantiquement
                    if pair_key in validation_results:
                        semantic_result = validation_results[pair_key]
                        if semantic_result['valid']:
                            print(f"   ‚úÖ Conserv√© : {original_term} ‚Üí {snomed_term}")
                            current_snomed_term = snomed_term
                            # V√âRIFICATION FINALE : Si le terme original est une correspondance exacte pour ce code,
                            # s'assurer que le snomed_term EST le terme original.
                            # Ceci est redondant si le flux de donn√©es est parfait, mais sert de garde-fou.
                            if self.validator.find_exact_term_code(original_term) == term_data['snomed_code']:
                                current_snomed_term = original_term
                                print(f"   üõ°Ô∏è GARDE-FOU (Phase 5) : Pour {original_term} ({term_data['snomed_code']}), snomed_term forc√© √† '{current_snomed_term}'")
                            entity = {
                                'term': term_data['term'],
                                'snomed_code': term_data['snomed_code'],
                                'snomed_term': current_snomed_term,
                                'category': self._categorize_by_snomed_code(term_data['snomed_code']),
                                'negation': term_data.get('negation', 'positive'),
                                'family': term_data.get('family', 'patient'),
                                'suspicion': term_data.get('suspicion', 'confirmed'),
                                'antecedent': term_data.get('antecedent', 'current')
                            }
                            final_validated.append(entity)
                        else:
                            print(f"   ‚ùå Rejet√© : {original_term} ‚Üí {snomed_term} ({semantic_result['reason']})")
                            rejected_terms.append({
                                'term': original_term,
                                'reason': semantic_result['reason']
                            })
                    else:
                        # Terme identique (pas besoin de validation s√©mantique) -> conserv√© automatiquement
                        print(f"   ‚úÖ Identique : {original_term} ‚Üí {snomed_term}")
                        current_snomed_term = snomed_term
                        # V√âRIFICATION FINALE : Si le terme original est une correspondance exacte pour ce code,
                        # s'assurer que le snomed_term EST le terme original.
                        # Ceci est redondant si le flux de donn√©es est parfait, mais sert de garde-fou.
                        if self.validator.find_exact_term_code(original_term) == term_data['snomed_code']:
                            current_snomed_term = original_term
                            print(f"   üõ°Ô∏è GARDE-FOU (Phase 5) : Pour {original_term} ({term_data['snomed_code']}), snomed_term forc√© √† '{current_snomed_term}'")
                        entity = {
                            'term': term_data['term'],
                            'snomed_code': term_data['snomed_code'],
                            'snomed_term': current_snomed_term,
                            'category': self._categorize_by_snomed_code(term_data['snomed_code']),
                            'negation': term_data.get('negation', 'positive'),
                            'family': term_data.get('family', 'patient'),
                            'suspicion': term_data.get('suspicion', 'confirmed'),
                            'antecedent': term_data.get('antecedent', 'current')
                        }
                        final_validated.append(entity)
            
            semantic_time = time.time() - semantic_start
            
            # === D√âDUPLICATION FINALE PAR TERME ORIGINAL ===
            # Si m√™me terme original avec codes diff√©rents ‚Üí garder le plus proche s√©mantiquement
            print(f"üîÑ D√©duplication finale par terme original...")
            final_deduplicated = []
            seen_terms = {}
            
            for entity in final_validated:
                original_term = entity['term'].lower()
                snomed_term = entity['snomed_term'].lower()
                
                if original_term not in seen_terms:
                    # Premier terme de ce type
                    seen_terms[original_term] = entity
                    final_deduplicated.append(entity)
                else:
                    # Doublon d√©tect√© - choisir le meilleur
                    existing_entity = seen_terms[original_term]
                    existing_snomed = existing_entity['snomed_term'].lower()
                    
                    # Priorit√© : terme identique > terme diff√©rent
                    if original_term == snomed_term and original_term != existing_snomed:
                        # Le nouveau est identique, l'ancien non ‚Üí remplacer
                        print(f"   üîÑ Remplacement: '{entity['term']}' ‚Üí '{entity['snomed_term']}' (identique) au lieu de ‚Üí '{existing_entity['snomed_term']}'")
                        final_deduplicated.remove(existing_entity)
                        final_deduplicated.append(entity)
                        seen_terms[original_term] = entity
                    elif original_term == existing_snomed and original_term != snomed_term:
                        # L'ancien est identique, le nouveau non ‚Üí garder l'ancien
                        print(f"   ‚úÖ Conserv√©: '{existing_entity['term']}' ‚Üí '{existing_entity['snomed_term']}' (identique) au lieu de ‚Üí '{entity['snomed_term']}'")
                    else:
                        # Cas ambigus ‚Üí garder le premier
                        print(f"   ‚ö†Ô∏è  Doublon gard√© premier: '{existing_entity['term']}' ‚Üí '{existing_entity['snomed_term']}' vs ‚Üí '{entity['snomed_term']}'")
            
            final_validated = final_deduplicated
            print(f"‚ú® Apr√®s d√©duplication finale : {len(final_validated)} termes uniques")
            
            print(f"üéØ Apr√®s validation s√©mantique : {len(final_validated)}/{len(unique_terms)} termes conserv√©s (‚è±Ô∏è {semantic_time:.2f}s)")
            
            if rejected_terms:
                print(f"üóëÔ∏è Rejet√©s pour incoh√©rence s√©mantique : {len(rejected_terms)}")
                for rejected in rejected_terms:
                    print(f"   ‚Ä¢ {rejected['term']} : {rejected['reason']}")
        
        total_validation_time = time.time() - validation_phase_start
        print(f"‚úÖ Phase validation compl√®te termin√©e en ‚è±Ô∏è {total_validation_time:.2f}s")
        
        # === PHASE 5 : R√âSULTATS FINAUX ===
        # Cat√©gorisation des r√©sultats finaux
        final_findings = []
        final_procedures = []
        final_body_structures = []
        
        for term_data in final_validated:
            # D√©tection automatique de cat√©gorie bas√©e sur le code SNOMED
            category = self._categorize_by_snomed_code(term_data['snomed_code'])
            
            current_snomed_term = term_data['snomed_term']
            # V√âRIFICATION FINALE : Si le terme original est une correspondance exacte pour ce code,
            # s'assurer que le snomed_term EST le terme original.
            if self.validator.find_exact_term_code(term_data['term']) == term_data['snomed_code']:
                current_snomed_term = term_data['term']
                print(f"   üõ°Ô∏è GARDE-FOU (Phase 5) : Pour {term_data['term']} ({term_data['snomed_code']}), snomed_term forc√© √† '{current_snomed_term}'")

            entity = {
                'term': term_data['term'],
                'snomed_code': term_data['snomed_code'],
                'snomed_term': current_snomed_term,
                'category': category,
                'negation': term_data.get('negation', 'positive'),
                'family': term_data.get('family', 'patient'),
                'suspicion': term_data.get('suspicion', 'confirmed'),
                'antecedent': term_data.get('antecedent', 'current')
            }
            
            if 'finding' in category.lower() or 'disorder' in category.lower():
                final_findings.append(entity)
            elif 'procedure' in category.lower():
                final_procedures.append(entity)
            else:
                final_body_structures.append(entity)
        
        # Calcul des statistiques de performance
        max_individual = max([stats[1] for stats in extraction_stats]) if extraction_stats else 0
        fusion_gain = len(unique_terms) - max_individual
        semantic_filtered = len(unique_terms) - len(final_validated)
        total_time = time.time() - start_time
        
        # R√©sultat final avec temps d√©taill√©s
        result = {
            'entities': {
                'findings': final_findings,
                'procedures': final_procedures,
                'body_structures': final_body_structures
            },
            'statistics': {
                'extractions': extraction_stats,
                'before_fusion': max_individual,
                'after_fusion': len(unique_terms),
                'after_semantic': len(final_validated),
                'fusion_gain': fusion_gain,
                'semantic_filtered': semantic_filtered,
                'times': {
                    'parallel_extractions': parallel_time,
                    'individual_times': individual_times,
                    'sequential_equivalent': sum(individual_times),
                    'parallel_gain': sum(individual_times) - parallel_time,
                    'validation_phase': total_validation_time,
                    'fusion': fusion_time,
                    'semantic_validation': semantic_time,
                    'total': total_time
                }
            }
        }
        
        # Affichage des r√©sultats avec temps d√©taill√©s
        print(f"\nüéØ R√âSULTAT FINAL DE LA FUSION V2 :")
        print(f"   üîç {len(final_findings)} constatations cliniques")
        print(f"   ‚öïÔ∏è  {len(final_procedures)} proc√©dures/traitements")
        print(f"   ü´Ä {len(final_body_structures)} structures corporelles")
        print(f"   üìä TOTAL : {len(final_validated)} entit√©s valid√©es")
        
        print(f"\nüìà STATISTIQUES PAR EXTRACTION :")
        for extraction_num, valid_count, total_count in extraction_stats:
            percentage = (valid_count/total_count*100) if total_count > 0 else 0
            print(f"   Extraction {extraction_num} : {valid_count}/{total_count} ({percentage:.1f}%)")
        
        print(f"\nüöÄ PERFORMANCE DE LA FUSION V2 :")
        print(f"   üìä Avant fusion : max {max_individual} entit√©s valid√©es")
        print(f"   ‚ú® Apr√®s fusion SNOMED : {len(unique_terms)} entit√©s uniques")
        print(f"   üß† Apr√®s validation s√©mantique : {len(final_validated)} entit√©s coh√©rentes")
        print(f"   üìà GAIN fusion : +{fusion_gain} entit√©s suppl√©mentaires")
        print(f"   üõ°Ô∏è FILTRAGE s√©mantique : -{semantic_filtered} incoh√©rences √©limin√©es")
        
        print(f"\n‚è±Ô∏è CHRONOM√âTRAGE D√âTAILL√â :")
        print(f"   üöÄ Extractions parall√®les : {parallel_time:.2f}s")
        print(f"   üîÑ √âquivalent s√©quentiel : {sum(individual_times):.2f}s")
        print(f"   üí® Gain parall√©lisme : -{sum(individual_times) - parallel_time:.2f}s")
        print(f"   üîç Phase validation : {total_validation_time:.2f}s")
        print(f"   üß† Validation s√©mantique : {semantic_time:.2f}s")
        print(f"   üéØ TEMPS TOTAL : {total_time:.2f}s")
        
        return result
    
    async def _validate_semantic_coherence_batch(self, term_pairs: list) -> dict:
        """
        Validation s√©mantique hybride group√©e des correspondances SNOMED CT
        Combine filtrage math√©matique rapide + LLM Gemini Flash pour les cas ambigus
        """
        from difflib import SequenceMatcher
        import time
        
        def calculate_math_score(gemini_term: str, official_term: str) -> float:
            """Score math√©matique rapide combinant plusieurs m√©triques"""
            
            # 1. Similarit√© Levenshtein
            levenshtein = SequenceMatcher(None, gemini_term.lower(), official_term.lower()).ratio()
            
            # 2. Mots en commun
            words_a = set(gemini_term.lower().split())
            words_b = set(official_term.lower().split())
            word_overlap = len(words_a.intersection(words_b)) / max(len(words_a), len(words_b)) if words_a or words_b else 0
            
            # 3. Contenance (un terme contient l'autre)
            a_clean = gemini_term.lower().strip()
            b_clean = official_term.lower().strip()
            contains = 1.0 if (a_clean in b_clean or b_clean in a_clean) else 0.0
            
            # Score global pond√©r√©
            return (levenshtein * 0.3 + word_overlap * 0.4 + contains * 0.3)
        
        def llm_validate_batch(llm_pairs: list) -> dict:
            """Validation LLM group√©e pour les cas ambigus"""
            if not llm_pairs:
                return {}
            
            # Construire le prompt group√©
            pairs_text = ""
            for i, (gemini_term, official_term) in enumerate(llm_pairs):
                pairs_text += f'{i+1}. "{gemini_term}" ‚Üî "{official_term}"\n'
            
            prompt = f"""Tu es un expert m√©dical. Analyse si chaque paire de termes m√©dicaux d√©signe le M√äME concept clinique :

{pairs_text}

R√©ponds EXACTEMENT par ce format JSON :
{{
    "validations": [
        {{"paire": 1, "meme_concept": true}},
        {{"paire": 2, "meme_concept": false}},
        etc.
    ]
}}

R√®gles :
- true = m√™me concept clinique (identique ou √©quivalent)
- false = concepts cliniques diff√©rents"""

            try:
                start_time = time.time()
                response = self.model.generate_content(prompt)
                llm_duration = time.time() - start_time
                
                response_text = response.text.strip()
                
                # Parser la r√©ponse JSON group√©e
                import json
                try:
                    # Extraire le JSON de la r√©ponse
                    json_start = response_text.find('{')
                    json_end = response_text.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = response_text[json_start:json_end]
                        result = json.loads(json_str)
                        
                        # Convertir en dictionnaire index√©
                        batch_results = {}
                        validations = result.get("validations", [])
                        
                        for validation in validations:
                            paire_num = validation.get('paire')
                            meme_concept = validation.get('meme_concept')
                            
                            if paire_num is not None and meme_concept is not None:
                                paire_idx = paire_num - 1
                                if 0 <= paire_idx < len(llm_pairs):
                                    pair_dict = llm_pairs[paire_idx]
                                    if meme_concept:
                                        batch_results[paire_idx] = {
                                            "valid": True,
                                            "confidence": 1.0,
                                            "reason": "Concept identique",
                                            "duration": llm_duration / len(llm_pairs)
                                        }
                                    else:
                                        batch_results[paire_idx] = {
                                            "valid": False,
                                            "confidence": 0.0,
                                            "reason": "Concept diff√©rent",
                                            "duration": llm_duration / len(llm_pairs)
                                        }
                        
                        # Compl√©ter les paires manquantes
                        for i in range(len(llm_pairs)):
                            if i not in batch_results:
                                batch_results[i] = {
                                    "valid": False,
                                    "confidence": 0.0,
                                    "reason": "Paire non trouv√©e dans la r√©ponse",
                                    "duration": llm_duration / len(llm_pairs)
                                }
                        
                        return batch_results
                    else:
                        # Fallback en cas d'√©chec de parsing
                        return {i: {"valid": False, "confidence": 0.0, "reason": "√âchec parsing JSON", "duration": llm_duration / len(llm_pairs)} for i in range(len(llm_pairs))}
                        
                except json.JSONDecodeError as e:
                    # Fallback simple en cas d'erreur JSON
                    return {i: {"valid": False, "confidence": 0.0, "reason": f"Erreur JSON: {str(e)}", "duration": llm_duration / len(llm_pairs)} for i in range(len(llm_pairs))}
                    
            except Exception as e:
                return {i: {"valid": False, "reason": f"Erreur LLM: {str(e)}", "confidence": 0.0, "duration": 0} for i in range(len(llm_pairs))}
        
        if not term_pairs:
            return {}
        
        # Phase 1 : Tri math√©matique rapide
        math_results = []
        llm_cases = []
        llm_indices = []
        
        print(f"üîç Validation s√©mantique hybride : {len(term_pairs)} paires √† analyser")
        
        for i, (gemini_term, official_term) in enumerate(term_pairs):
            math_score = calculate_math_score(gemini_term, official_term)
            
            if math_score >= 0.5:
                # Cas √©vident : ACCEPTER directement
                result = {
                    'valid': True,
                    'confidence': math_score,
                    'method': 'mathematical',
                    'reason': f"Score math √©lev√© ({math_score:.3f})"
                }
                print(f"   ‚úÖ Math: '{gemini_term}' ‚Üí '{official_term}' (score: {math_score:.3f})")
            elif math_score <= 0.01:
                # Cas tr√®s √©vident : REJETER directement
                result = {
                    'valid': False,
                    'confidence': math_score,
                    'method': 'mathematical', 
                    'reason': f"Score math tr√®s bas ({math_score:.3f})"
                }
                print(f"   ‚ùå Math: '{gemini_term}' ‚Üí '{official_term}' (score: {math_score:.3f})")
            else:
                # Cas ambigu : pour LLM
                result = {
                    'valid': False,  # Sera mis √† jour apr√®s LLM
                    'confidence': 0.0,  # Sera mis √† jour apr√®s LLM
                    'method': 'hybrid',
                    'reason': f"Score math ambigu ({math_score:.3f}) ‚Üí LLM"
                }
                llm_cases.append((gemini_term, official_term))
                llm_indices.append(i)
                print(f"   ü§ñ LLM: '{gemini_term}' ‚Üí '{official_term}' (score: {math_score:.3f})")
            
            math_results.append(result)
        
        # Phase 2 : Validation LLM group√©e
        if llm_cases:
            print(f"ü§ñ Validation LLM group√©e : {len(llm_cases)} paires ambigu√´s")
            
            start_llm = time.time()
            llm_batch_results = llm_validate_batch(llm_cases)
            total_llm_time = time.time() - start_llm
            
            print(f"‚úÖ LLM group√© termin√© en {total_llm_time:.2f}s")
            
            # Mettre √† jour les r√©sultats avec les validations LLM
            for batch_idx, original_idx in enumerate(llm_indices):
                if batch_idx in llm_batch_results:
                    llm_result = llm_batch_results[batch_idx]
                    result = math_results[original_idx]
                    
                    result['valid'] = llm_result.get('valid', False)
                    result['confidence'] = llm_result.get('confidence', 0.0)
                    result['reason'] = llm_result.get('reason', 'Analyse LLM')
                    
                    status = "‚úÖ" if result['valid'] else "‚ùå"
                    gemini_term, official_term = llm_cases[batch_idx]
                    print(f"   {status} LLM: '{gemini_term}' ‚Üí '{official_term}' (confiance: {result['confidence']:.2f})")
                    print(f"      ‚îî‚îÄ {result['reason']}")
        
        # Convertir en dictionnaire index√© pour le retour
        final_results = {}
        for i, result in enumerate(math_results):
            final_results[i] = result
        
        # Statistiques
        valid_count = sum(1 for r in math_results if r['valid'])
        math_count = sum(1 for r in math_results if r['method'] == 'mathematical')
        llm_count = len(llm_cases)
        
        print(f"üìä Validation termin√©e : {valid_count}/{len(term_pairs)} valid√©es")
        print(f"   üî¢ Math : {math_count}/{len(term_pairs)} ({math_count/len(term_pairs)*100:.1f}%)")
        print(f"   ü§ñ LLM : {llm_count}/{len(term_pairs)} ({llm_count/len(term_pairs)*100:.1f}%)")
        
        return final_results 

    def _categorize_by_snomed_code(self, snomed_code):
        """
        Cat√©gorise automatiquement une entit√© bas√©e sur son code SNOMED
        
        Args:
            snomed_code (str): Code SNOMED CT
            
        Returns:
            str: Cat√©gorie d√©termin√©e
        """
        # R√®gles de cat√©gorisation bas√©es sur les hi√©rarchies SNOMED
        # Ces codes correspondent aux grandes hi√©rarchies SNOMED CT
        
        # Findings/Disorders (domaine clinique)
        if snomed_code.startswith(('271', '40', '38', '41', '27', '36', '23', '25', '42')):
            return "Clinical finding"
        
        # Procedures (interventions)  
        elif snomed_code.startswith(('71', '77', '23', '18', '38', '89', '17', '18')):
            return "Procedure"
            
        # Body structures (anatomie)
        elif snomed_code.startswith(('51', '81', '15', '79', '24', '36', '12', '91')):
            return "Body structure"
            
        # Observable entity (observations)
        elif snomed_code.startswith(('36', '24', '25')):
            return "Observable entity"
            
        # Substances (m√©dicaments, substances)
        elif snomed_code.startswith(('44', '37', '39', '41')):
            return "Substance"
            
        # Par d√©faut, cat√©goriser comme finding
        else:
            return "Clinical finding"
    
    def _security_check(self):
        """V√©rification de s√©curit√© des limites API"""
        can_proceed, message = security_manager.can_make_request()
        if not can_proceed:
            print(f"üö´ EXTRACTION BLOQU√âE : {message}")
            return False
        return True
    
    def extract_medical_entities(self, text, use_context_modifiers=True):
        """
        Extraction d'entit√©s m√©dicales √† partir de texte brut
        Compatible avec la m√©thode V2 asynchrone
        """
        try:
            # Cr√©er un objet MedicalNote temporaire
            medical_note = MedicalNote(
                patient_id="TEMP_001",
                patient_name="Patient Temporaire",
                date="2025-01-01",
                doctor="Dr. Extracteur",
                content=text,
                specialty="Extraction automatique"
            )
            
            # Utiliser la m√©thode d'extraction existante
            extraction = self.extract_snomed_info(medical_note)
            
            # Convertir au format attendu par la m√©thode V2
            findings = []
            procedures = []
            body_structures = []
            
            for finding in extraction.clinical_findings:
                findings.append({
                    'term': finding.term,
                    'snomed_code': finding.snomed_code,
                    'category': 'clinical_finding',
                    # R√©cup√©rer TOUS les modifieurs contextuels
                    'negation': getattr(finding, 'negation', 'positive'),
                    'family': getattr(finding, 'family', 'patient'),
                    'suspicion': getattr(finding, 'suspicion', 'confirmed'),
                    'antecedent': getattr(finding, 'antecedent', 'current')
                })
            
            for procedure in extraction.procedures:
                procedures.append({
                    'term': procedure.term,
                    'snomed_code': procedure.snomed_code,
                    'category': 'procedure',
                    # R√©cup√©rer TOUS les modifieurs contextuels
                    'negation': getattr(procedure, 'negation', 'positive'),
                    'family': getattr(procedure, 'family', 'patient'),
                    'suspicion': getattr(procedure, 'suspicion', 'confirmed'),
                    'antecedent': getattr(procedure, 'antecedent', 'current')
                })
            
            for structure in extraction.body_structures:
                body_structures.append({
                    'term': structure.term,
                    'snomed_code': structure.snomed_code,
                    'category': 'body_structure',
                    # R√©cup√©rer TOUS les modifieurs contextuels
                    'negation': getattr(structure, 'negation', 'positive'),
                    'family': getattr(structure, 'family', 'patient'),
                    'suspicion': getattr(structure, 'suspicion', 'confirmed'),
                    'antecedent': getattr(structure, 'antecedent', 'current')
                })
            
            return {
                'entities': {
                    'findings': findings,
                    'procedures': procedures,
                    'body_structures': body_structures
                }
            }
            
        except Exception as e:
            print(f"‚ùå Erreur extraction_medical_entities: {str(e)}")
            return None 