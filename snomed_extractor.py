import google.generativeai as genai
import json
import re
from typing import Dict, Any
from config import Config
from models import MedicalNote, SNOMEDExtraction, ClinicalFinding, Procedure, BodyStructure
from api_security import security_manager
import asyncio
import time
from snomed_validator import SNOMEDValidator

class SNOMEDExtractor:
    """Extracteur d'informations SNOMED CT Ã  partir de notes mÃ©dicales"""
    
    def __init__(self):
        """Initialiser l'extracteur avec le modÃ¨le Gemini"""
        Config.validate()
        genai.configure(api_key=Config.GOOGLE_API_KEY)
        # ModÃ¨le configurable
        self.model_name = Config.GEMINI_MODEL
        self.model = genai.GenerativeModel(self.model_name)
    
    def set_model(self, model_name: str):
        """Changer le modÃ¨le utilisÃ©"""
        self.model_name = model_name
        self.model = genai.GenerativeModel(self.model_name)
        print(f"ðŸ”„ ModÃ¨le changÃ© vers : {model_name}")
    
    def create_extraction_prompt(self, medical_note: str) -> str:
        """CrÃ©er un prompt Ã©ducatif optimisÃ© pour extraction complÃ¨te"""
        prompt = f"""Dans un contexte Ã©ducatif de classification mÃ©dicale, analyse ce cas d'Ã©tude :

{medical_note}

Extrais UNIQUEMENT les concepts mÃ©dicaux appartenant aux 3 hiÃ©rarchies SNOMED CT ciblÃ©es :

1. **CLINICAL FINDING** (Constatations cliniques) :
   - SymptÃ´mes observÃ©s (ex: Ã©ruption cutanÃ©e, prurit)
   - Signes cliniques (ex: lÃ©sions vÃ©siculeuses)
   - Diagnostics Ã©tablis (ex: varicelle)
   - Ã‰tats pathologiques

2. **PROCEDURE** (Interventions/ProcÃ©dures) :
   - Traitements administrÃ©s (ex: antihistaminique oral)
   - Soins mÃ©dicaux (ex: soins locaux)
   - Recommandations thÃ©rapeutiques (ex: Ã©viction scolaire)
   - Actes mÃ©dicaux

3. **BODY STRUCTURE** (Structures corporelles) :
   - Parties anatomiques mentionnÃ©es (ex: membres, tronc)
   - Organes, rÃ©gions corporelles
   - Structures anatomiques

**EXCLURE** : antÃ©cÃ©dents, contexte familial, informations administratives, expositions

Format JSON requis :
{{
  "concepts_medicaux": [
    {{
      "concept": "concept mÃ©dical normalisÃ©",
      "categorie": "clinical_finding/procedure/body_structure",
      "code_classification": "code SNOMED CT numÃ©rique unique pour ce concept",
      "negation": "positive/negative",
      "famille": "patient/family", 
      "suspicion": "confirmed/suspected",
      "antecedent": "current/history"
    }}
  ]
}}

IMPORTANT : Assigne un code SNOMED CT diffÃ©rent et appropriÃ© pour chaque concept mÃ©dical.
Exemples de codes : 
- Varicelle: 38907003
- Ã‰ruption cutanÃ©e: 271807003  
- Antihistaminique: 432102000
- Membres: 445662006

RÃˆGLES pour les modifieurs :
- nÃ©gation : "positive" si prÃ©sent, "negative" si absent/niÃ©
- famille : "patient" pour le patient, "family" pour antÃ©cÃ©dent familial
- suspicion : "confirmed" si certain, "suspected" si suspectÃ©
- antecedent : "current" si actuel, "history" si antÃ©cÃ©dent mÃ©dical

Retourne uniquement le JSON avec les concepts des 3 hiÃ©rarchies ciblÃ©es."""
        return prompt
    
    def extract_snomed_info(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """Extraction optimisÃ©e ONE-SHOT avec codes SNOMED CT et modifieurs contextuels"""
        try:
            # ðŸ›¡ï¸ SÃ‰CURITÃ‰ : VÃ©rifier les limites avant l'appel API
            can_proceed, message = security_manager.can_make_request()
            if not can_proceed:
                print(f"ðŸš« EXTRACTION BLOQUÃ‰E : {message}")
                print("â° RÃ©essayez plus tard ou contactez l'administrateur")
                return self._create_empty_extraction(medical_note)
            
            print(f"ðŸ”’ SÃ©curitÃ© : {message}")
            print("ðŸ” Extraction ONE-SHOT avec modifieurs contextuels...")
            
            prompt = self.create_extraction_prompt(medical_note.content)
            
            response = self.model.generate_content(prompt)
            
            # ðŸ›¡ï¸ SÃ‰CURITÃ‰ : Enregistrer l'appel API rÃ©ussi
            security_manager.record_api_call(estimated_cost=0.015)  # CoÃ»t estimÃ© pour Gemini Flash
            security_manager.print_usage_warning()
            
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                
                if hasattr(candidate, 'finish_reason') and candidate.finish_reason == 2:
                    print("âŒ Extraction bloquÃ©e par filtres de sÃ©curitÃ©")
                    return self._create_empty_extraction(medical_note)
                
                if hasattr(response, 'text') and response.text:
                    response_text = response.text
                elif hasattr(candidate.content, 'parts') and candidate.content.parts:
                    response_text = "".join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
                else:
                    print("âŒ Pas de texte dans la rÃ©ponse")
                    return self._create_empty_extraction(medical_note)
            else:
                print("âŒ Pas de candidat dans la rÃ©ponse")
                return self._create_empty_extraction(medical_note)
            
            print("âœ… RÃ©ponse reÃ§ue, parsing...")
            
            # Parser la rÃ©ponse simple
            parsed_data = self.parse_gemini_response(response_text)
            
            # Convertir le format en objets SNOMED CT
            clinical_findings = []
            procedures = []
            body_structures = []
            
            # Traiter les termes mÃ©dicaux avec codes et modifieurs fournis par Gemini
            for terme_data in parsed_data.get("concepts_medicaux", []):
                terme = terme_data.get("concept", "")
                categorie = terme_data.get("categorie", "").lower()
                code_snomed = terme_data.get("code_classification", "UNKNOWN")
                
                # Extraire les modifieurs contextuels
                negation = terme_data.get("negation", "positive")
                family = terme_data.get("famille", "patient")  # Note: "famille" en franÃ§ais dans le JSON
                suspicion = terme_data.get("suspicion", "confirmed")
                antecedent = terme_data.get("antecedent", "current")
                
                if "symptome" in categorie or "diagnostic" in categorie or "finding" in categorie or "clinical_finding" in categorie:
                    clinical_findings.append(ClinicalFinding(
                        term=terme,
                        description=f"Constatation clinique : {terme}",
                        context=f"Extrait de la note mÃ©dicale",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "traitement" in categorie or "procedure" in categorie or "intervention" in categorie:
                    procedures.append(Procedure(
                        term=terme,
                        description=f"Intervention/ProcÃ©dure : {terme}",
                        context=f"Extrait de la note mÃ©dicale",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "anatomie" in categorie or "structure" in categorie or "corps" in categorie or "body_structure" in categorie:
                    body_structures.append(BodyStructure(
                        term=terme,
                        description=f"Structure corporelle : {terme}",
                        context=f"Extrait de la note mÃ©dicale",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                else:
                    # Ignorer les termes qui ne correspondent Ã  aucune des 3 hiÃ©rarchies ciblÃ©es
                    print(f"âš ï¸  Terme ignorÃ© (hors hiÃ©rarchies ciblÃ©es) : {terme} ({categorie})")
                    continue
            
            print(f"âœ… Extraction rÃ©ussie : {len(clinical_findings)} constatations, {len(procedures)} procÃ©dures, {len(body_structures)} structures")
            return SNOMEDExtraction(
                original_note=medical_note,
                clinical_findings=clinical_findings,
                procedures=procedures,
                body_structures=body_structures
            )
            
        except Exception as e:
            print(f"âŒ Erreur extraction : {e}")
            return self._create_empty_extraction(medical_note)
    
    def parse_gemini_response(self, response_text: str) -> Dict[str, Any]:
        """Parser la rÃ©ponse JSON de Gemini"""
        try:
            # Nettoyer la rÃ©ponse pour extraire le JSON
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            else:
                print("âŒ Aucun JSON trouvÃ© dans la rÃ©ponse")
                return {"concepts_medicaux": []}
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur parsing JSON : {e}")
            print(f"RÃ©ponse reÃ§ue : {response_text[:500]}...")
            return {"concepts_medicaux": []}
    
    def _extract_response_text(self, response) -> str:
        """Extraire le texte d'une rÃ©ponse Gemini"""
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason == 2:
                print("âŒ RÃ©ponse bloquÃ©e par filtres de sÃ©curitÃ©")
                return ""
            
            if hasattr(response, 'text') and response.text:
                return response.text
            elif hasattr(candidate.content, 'parts') and candidate.content.parts:
                return "".join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
        
        print("âŒ Pas de texte dans la rÃ©ponse")
        return ""
    
    def _create_empty_extraction(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """CrÃ©er une extraction vide en cas d'erreur"""
        return SNOMEDExtraction(
            original_note=medical_note,
            clinical_findings=[],
            procedures=[],
            body_structures=[]
        ) 
    
    def extract_triple_parallel(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """Extraction avec 3 appels parallÃ¨les pour amÃ©liorer la robustesse"""
        try:
            # ðŸ›¡ï¸ SÃ‰CURITÃ‰ : VÃ©rifier les limites avant les appels API
            can_proceed, message = security_manager.can_make_request()
            if not can_proceed:
                print(f"ðŸš« EXTRACTION BLOQUÃ‰E : {message}")
                return self._create_empty_extraction(medical_note)
            
            print(f"ðŸ”’ SÃ©curitÃ© : {message}")
            print("ðŸ” Extraction TRIPLE PARALLÃˆLE commencÃ©e...")
            
            prompt = self.create_extraction_prompt(medical_note.content)
            
            # Faire 3 appels parallÃ¨les avec le mÃªme prompt
            print("ðŸ“‹ Lancement de 3 appels parallÃ¨les Ã  Gemini...")
            
            responses = []
            for i in range(3):
                print(f"ðŸ”„ Appel {i+1}/3...")
                response = self.model.generate_content(prompt)
                security_manager.record_api_call(estimated_cost=0.02)
                responses.append(response)
            
            print("âœ… 3 appels terminÃ©s, analyse des rÃ©ponses...")
            
            # Collecter tous les termes de tous les appels
            all_terms = []
            
            for i, response in enumerate(responses):
                print(f"ðŸ“Š Analyse rÃ©ponse {i+1}/3...")
                response_text = self._extract_response_text(response)
                if response_text:
                    parsed_data = self.parse_gemini_response(response_text)
                    terms = parsed_data.get("concepts_medicaux", [])
                    print(f"   â†’ {len(terms)} termes extraits")
                    all_terms.extend(terms)
                else:
                    print(f"   â†’ Ã‰chec de l'extraction")
            
            print(f"ðŸ”„ Total combinÃ© : {len(all_terms)} termes")
            
            # DÃ©dupliquer par terme (garder le premier trouvÃ©)
            seen_terms = set()
            unique_terms = []
            for term_data in all_terms:
                terme = term_data.get("concept", "").lower().strip()
                if terme and terme not in seen_terms:
                    seen_terms.add(terme)
                    unique_terms.append(term_data)
            
            print(f"âœ… AprÃ¨s dÃ©duplication : {len(unique_terms)} termes uniques")
            
            # Convertir en objets SNOMED CT
            clinical_findings = []
            procedures = []
            body_structures = []
            
            for terme_data in unique_terms:
                terme = terme_data.get("concept", "")
                categorie = terme_data.get("categorie", "").lower()
                code_snomed = terme_data.get("code_classification", "UNKNOWN")
                
                # Extraire les modifieurs contextuels
                negation = terme_data.get("negation", "positive")
                family = terme_data.get("famille", "patient")
                suspicion = terme_data.get("suspicion", "confirmed")
                antecedent = terme_data.get("antecedent", "current")
                
                if "symptome" in categorie or "diagnostic" in categorie or "finding" in categorie or "clinical_finding" in categorie:
                    clinical_findings.append(ClinicalFinding(
                        term=terme,
                        description=f"Constatation clinique : {terme}",
                        context="Extrait par mÃ©thode triple parallÃ¨le",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "traitement" in categorie or "procedure" in categorie or "intervention" in categorie:
                    procedures.append(Procedure(
                        term=terme,
                        description=f"Intervention/ProcÃ©dure : {terme}",
                        context="Extrait par mÃ©thode triple parallÃ¨le",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
                elif "structure" in categorie or "body_structure" in categorie:
                    body_structures.append(BodyStructure(
                        term=terme,
                        description=f"Structure corporelle : {terme}",
                        context="Extrait par mÃ©thode triple parallÃ¨le",
                        snomed_code=code_snomed,
                        snomed_term_fr=terme,
                        negation=negation,
                        family=family,
                        suspicion=suspicion,
                        antecedent=antecedent
                    ))
            
            print(f"âœ… Extraction TRIPLE PARALLÃˆLE rÃ©ussie : {len(clinical_findings)} constatations, {len(procedures)} procÃ©dures, {len(body_structures)} structures")
            security_manager.print_usage_warning()
            
            return SNOMEDExtraction(
                original_note=medical_note,
                clinical_findings=clinical_findings,
                procedures=procedures,
                body_structures=body_structures
            )
            
        except Exception as e:
            print(f"âŒ Erreur extraction triple parallÃ¨le : {e}")
            return self._create_empty_extraction(medical_note)
    
    def extract_triple_with_validation_fusion(self, medical_note: MedicalNote) -> SNOMEDExtraction:
        """
        MÃ‰THODE ULTIME : 3 extractions + validation + fusion de TOUS les rÃ©sultats validÃ©s
        Collecte et combine tous les termes validÃ©s des 3 extractions pour maximiser le rÃ©sultat
        """
        try:
            # ðŸ›¡ï¸ SÃ‰CURITÃ‰ : VÃ©rifier les limites avant les appels API
            can_proceed, message = security_manager.can_make_request()
            if not can_proceed:
                print(f"ðŸš« EXTRACTION BLOQUÃ‰E : {message}")
                return self._create_empty_extraction(medical_note)
            
            print(f"ðŸ”’ SÃ©curitÃ© : {message}")
            print("ðŸŽ¯ EXTRACTION TRIPLE + VALIDATION + FUSION commencÃ©e...")
            
            # Charger le validateur une seule fois pour toutes les validations
            validator = SNOMEDValidator()
            print("âœ… Validateur SNOMED CT chargÃ©")
            
            # Lancer 3 extractions sÃ©quentielles avec validation immÃ©diate
            all_valid_items = []
            extraction_stats = []
            
            for i in range(3):
                print(f"\nðŸ”„ === EXTRACTION {i+1}/3 ===")
                
                # Extraction avec Gemini
                extraction = self.extract_snomed_info(medical_note)
                security_manager.record_api_call(estimated_cost=0.02)
                
                # Collecter tous les items extraits
                all_items = (extraction.clinical_findings + 
                           extraction.procedures + 
                           extraction.body_structures)
                
                print(f"ðŸ“Š Extraction {i+1} : {len(all_items)} termes extraits")
                
                # Validation immÃ©diate des termes de cette extraction
                valid_items_this_round = []
                for item in all_items:
                    if validator.validate_code(item.snomed_code):
                        valid_items_this_round.append(item)
                
                print(f"âœ… Validation {i+1} : {len(valid_items_this_round)}/{len(all_items)} termes validÃ©s")
                
                # Ajouter Ã  la collection globale
                all_valid_items.extend(valid_items_this_round)
                
                extraction_stats.append({
                    'total': len(all_items),
                    'valid': len(valid_items_this_round),
                    'rate': (len(valid_items_this_round) / len(all_items) * 100) if len(all_items) > 0 else 0
                })
            
            print(f"\nðŸ”„ Total avant dÃ©duplication : {len(all_valid_items)} termes validÃ©s")
            
            # DÃ‰DUPLICATION par code SNOMED (pas par terme)
            seen_codes = set()
            unique_valid_items = []
            
            for item in all_valid_items:
                code = item.snomed_code
                if code and code not in seen_codes:
                    seen_codes.add(code)
                    unique_valid_items.append(item)
                    print(f"   âž• {item.term} ({code})")
                else:
                    print(f"   ðŸ”„ Doublon ignorÃ© : {item.term} ({code})")
            
            print(f"âœ¨ AprÃ¨s dÃ©duplication : {len(unique_valid_items)} termes uniques validÃ©s")
            
            # RÃ©organiser par type pour crÃ©er l'objet final
            final_clinical_findings = []
            final_procedures = []
            final_body_structures = []
            
            for item in unique_valid_items:
                if hasattr(item, '__class__'):
                    class_name = item.__class__.__name__
                    if class_name == 'ClinicalFinding':
                        final_clinical_findings.append(item)
                    elif class_name == 'Procedure':
                        final_procedures.append(item)
                    elif class_name == 'BodyStructure':
                        final_body_structures.append(item)
            
            # Statistiques finales
            print(f"\nðŸŽ¯ RÃ‰SULTAT FINAL DE LA FUSION :")
            print(f"   ðŸ” {len(final_clinical_findings)} constatations cliniques")
            print(f"   âš•ï¸  {len(final_procedures)} procÃ©dures/traitements")
            print(f"   ðŸ«€ {len(final_body_structures)} structures corporelles")
            print(f"   ðŸ“Š TOTAL : {len(unique_valid_items)} entitÃ©s validÃ©es")
            
            # Afficher les statistiques par extraction
            print(f"\nðŸ“ˆ STATISTIQUES PAR EXTRACTION :")
            for i, stats in enumerate(extraction_stats, 1):
                print(f"   Extraction {i} : {stats['valid']}/{stats['total']} ({stats['rate']:.1f}%)")
            
            # Calculer le gain vs mÃ©thode simple
            total_extractions = sum(stats['total'] for stats in extraction_stats)
            total_valid_before_fusion = sum(stats['valid'] for stats in extraction_stats)
            gain = len(unique_valid_items) - max(stats['valid'] for stats in extraction_stats)
            
            print(f"\nðŸš€ PERFORMANCE DE LA FUSION :")
            print(f"   ðŸ“Š Avant fusion : max {max(stats['valid'] for stats in extraction_stats)} entitÃ©s validÃ©es")
            print(f"   âœ¨ AprÃ¨s fusion : {len(unique_valid_items)} entitÃ©s uniques")
            print(f"   ðŸ“ˆ GAIN : +{gain} entitÃ©s supplÃ©mentaires !")
            
            security_manager.print_usage_warning()
            
            return SNOMEDExtraction(
                original_note=medical_note,
                clinical_findings=final_clinical_findings,
                procedures=final_procedures,
                body_structures=final_body_structures
            )
            
        except Exception as e:
            print(f"âŒ Erreur extraction triple + fusion : {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_extraction(medical_note)
    
    async def extract_triple_with_validation_fusion_v2(self, text, use_context_modifiers=True):
        """
        MÃ‰THODE ULTIME V2 : Triple extraction parallÃ¨le + validation SNOMED + validation sÃ©mantique finale
        
        Processus optimisÃ© :
        1. 3 extractions Gemini Pro EN PARALLÃˆLE (chronomÃ©trÃ©es)
        2. Validation SNOMED de chaque extraction (chronomÃ©trÃ©e)  
        3. Fusion + dÃ©duplication par code SNOMED (chronomÃ©trÃ©e)
        4. Validation sÃ©mantique hybride SUR LE TABLEAU FINAL SEULEMENT (chronomÃ©trÃ©e)
        
        Returns:
            dict: RÃ©sultats finaux avec statistiques dÃ©taillÃ©es et temps
        """
        print("ðŸŽ¯ EXTRACTION ULTIME V2 : Triple extraction parallÃ¨le + validation SNOMED + validation sÃ©mantique finale")
        start_time = time.time()
        
        # VÃ©rifications prÃ©liminaires
        if not self._security_check():
            return {"error": "Limites de sÃ©curitÃ© dÃ©passÃ©es"}
        
        # Initialiser le validator SNOMED
        if not hasattr(self, 'validator') or self.validator is None:
            print("âœ… Validateur SNOMED CT chargÃ©")
            self.validator = SNOMEDValidator()
        
        # === PHASE 1 : TRIPLE EXTRACTION PARALLÃˆLE ===
        parallel_start = time.time()
        print("ðŸš€ DÃ©but des 3 extractions en parallÃ¨le...")
        
        async def extract_single(extraction_num):
            """Extraction individuelle avec chronomÃ©trage"""
            extraction_start = time.time()
            print(f"ðŸ”„ === EXTRACTION {extraction_num}/3 ===")
            
            # CORRECTION : Utiliser asyncio.to_thread pour vraie parallÃ©lisation
            entities = await asyncio.to_thread(
                self.extract_medical_entities, 
                text, 
                use_context_modifiers
            )
            
            extraction_time = time.time() - extraction_start
            print(f"âœ… Extraction {extraction_num} terminÃ©e en â±ï¸ {extraction_time:.2f}s")
            return entities, extraction_time
        
        # ExÃ©cution des 3 extractions en parallÃ¨le  
        results = await asyncio.gather(
            extract_single(1),
            extract_single(2), 
            extract_single(3)
        )
        
        parallel_time = time.time() - parallel_start
        individual_times = [result[1] for result in results]
        print(f"ðŸŽ¯ 3 extractions parallÃ¨les terminÃ©es en â±ï¸ {parallel_time:.2f}s (vs {sum(individual_times):.2f}s sÃ©quentiel = Gain: {sum(individual_times) - parallel_time:.2f}s)")
        
        # === PHASE 2 : VALIDATION SNOMED AVEC CHRONOMÃ‰TRAGE ===
        validation_phase_start = time.time()
        print(f"\nðŸ” === VALIDATION SNOMED (3 extractions) ===")
        
        all_validated_terms = []
        extraction_stats = []
        
        for i, (entities_result, _) in enumerate(results):
            extraction_num = i + 1
            all_terms = []
            
            # Correction : accÃ¨s correct Ã  la structure des donnÃ©es
            if entities_result and 'entities' in entities_result:
                entities = entities_result['entities']
                
                # Collecte des termes avec structure corrigÃ©e ET modifieurs contextuels
                for finding in entities.get('findings', []):
                    all_terms.append({
                        'term': finding['term'],
                        'snomed_code': finding.get('snomed_code', 'UNKNOWN'),
                        'category': finding.get('category', 'clinical_finding'),
                        'negation': finding.get('negation', 'positive'),
                        'family': finding.get('family', 'patient'),
                        'suspicion': finding.get('suspicion', 'confirmed'),
                        'antecedent': finding.get('antecedent', 'current')
                    })
                for procedure in entities.get('procedures', []):
                    all_terms.append({
                        'term': procedure['term'],
                        'snomed_code': procedure.get('snomed_code', 'UNKNOWN'),
                        'category': procedure.get('category', 'procedure'),
                        'negation': procedure.get('negation', 'positive'),
                        'family': procedure.get('family', 'patient'),
                        'suspicion': procedure.get('suspicion', 'confirmed'),
                        'antecedent': procedure.get('antecedent', 'current')
                    })
                for structure in entities.get('body_structures', []):
                    all_terms.append({
                        'term': structure['term'],
                        'snomed_code': structure.get('snomed_code', 'UNKNOWN'),
                        'category': structure.get('category', 'body_structure'),
                        'negation': structure.get('negation', 'positive'),
                        'family': structure.get('family', 'patient'),
                        'suspicion': structure.get('suspicion', 'confirmed'),
                        'antecedent': structure.get('antecedent', 'current')
                    })
                
                print(f"ðŸ“Š Extraction {extraction_num} : {len(all_terms)} termes extraits")
            else:
                print(f"âŒ Extraction {extraction_num} : pas de donnÃ©es")
                continue
            
            # Validation SNOMED avec chronomÃ©trage ET prÃ©servation des modifieurs
            validation_start = time.time()
            validated = []
            valid_count = 0
            
            for term_data in all_terms:
                term = term_data['term']
                
                # ðŸŽ¯ NOUVELLE LOGIQUE PRIORITAIRE
                snomed_code = None
                snomed_term = None
                
                # ðŸ¥‡ PRIORITÃ‰ 1 : Recherche EXACTE du terme dans la base SNOMED
                exact_code = self.validator.find_exact_term_code(term)
                if exact_code:
                    snomed_code = exact_code
                    snomed_term = term 
                    print(f"   ðŸŽ¯ Terme EXACT trouvÃ© : {term} â†’ {exact_code} (UTILISE LE TERME EXACT : '{snomed_term}')")
                else:
                    # ðŸ¥ˆ PRIORITÃ‰ 2 : VÃ©rifier si le code de Gemini existe dans notre base
                    gemini_code = term_data.get('snomed_code', 'UNKNOWN')
                    if gemini_code != 'UNKNOWN' and self.validator.validate_code(gemini_code):
                        snomed_code = gemini_code
                        snomed_term = self.validator.get_french_term(gemini_code)
                        print(f"   âœ… Code Gemini validÃ© : {term} â†’ {gemini_code} ('{snomed_term}')")
                    else:
                        # ðŸ¥‰ PRIORITÃ‰ 3 : Fallback - chercher nous-mÃªmes
                        snomed_code = self.validator.find_closest_code(term)
                        if snomed_code:
                            snomed_term = self.validator.get_french_term(snomed_code)
                            print(f"   ðŸ” Code trouvÃ© par recherche : {term} â†’ {snomed_code}")
                        else:
                            print(f"   âŒ Aucun code valide trouvÃ© pour : {term} (Gemini: {gemini_code})")
                            continue
                
                if snomed_code and snomed_term:
                    validated.append({
                        'term': term,
                        'snomed_code': snomed_code,
                        'snomed_term': snomed_term,
                        'valid': True,
                        # PrÃ©server les modifieurs contextuels
                        'negation': term_data.get('negation', 'positive'),
                        'family': term_data.get('family', 'patient'),
                        'suspicion': term_data.get('suspicion', 'confirmed'),
                        'antecedent': term_data.get('antecedent', 'current'),
                        'category': term_data.get('category', 'clinical_finding')
                    })
                    valid_count += 1
                else:
                    print(f"   âŒ Aucun code valide trouvÃ© pour : {term} (Gemini: {gemini_code})")
            
            validation_time = time.time() - validation_start
            print(f"âœ… Validation SNOMED {extraction_num} : {valid_count}/{len(all_terms)} termes validÃ©s (â±ï¸ {validation_time:.2f}s)")
            
            # Collecte des termes validÃ©s
            for term_data in validated:
                if term_data['valid']:
                    all_validated_terms.append(term_data)
            
            extraction_stats.append((extraction_num, valid_count, len(all_terms)))
        
        # === PHASE 3 : FUSION ET DÃ‰DUPLICATION ===
        fusion_start = time.time()
        print(f"\nðŸ”„ === FUSION ET DÃ‰DUPLICATION ===")
        print(f"Total avant dÃ©duplication : {len(all_validated_terms)} termes validÃ©s SNOMED")
        
        unique_terms = {}
        for term_data in all_validated_terms:
            code = term_data['snomed_code']
            if code not in unique_terms:
                print(f"   âž• {term_data['term']} ({code})")
                unique_terms[code] = term_data
            else:
                print(f"   ðŸ”„ Doublon ignorÃ© : {term_data['term']} ({code})")
        
        fusion_time = time.time() - fusion_start
        print(f"âœ¨ AprÃ¨s dÃ©duplication : {len(unique_terms)} termes uniques validÃ©s SNOMED (â±ï¸ {fusion_time:.2f}s)")
        
        # === PHASE 4 : VALIDATION SÃ‰MANTIQUE SUR LE TABLEAU FINAL ===
        semantic_start = time.time()
        print(f"\nðŸ§  === VALIDATION SÃ‰MANTIQUE HYBRIDE ===")
        
        # PrÃ©paration des paires pour validation sÃ©mantique
        semantic_pairs = []
        for term_data in unique_terms.values():
            original_term = term_data['term']
            snomed_term = term_data['snomed_term']
            if original_term.lower() != snomed_term.lower():
                semantic_pairs.append((original_term, snomed_term))
        
        if not semantic_pairs:
            print("ðŸ“Š Aucune validation sÃ©mantique nÃ©cessaire : tous les termes sont identiques")
            final_validated = []
            for term_data in unique_terms.values():
                entity = {
                    'term': term_data['term'],
                    'snomed_code': term_data['snomed_code'],
                    'snomed_term': term_data['snomed_term'],
                    'category': self._categorize_by_snomed_code(term_data['snomed_code']),
                    'negation': term_data.get('negation', 'positive'),
                    'family': term_data.get('family', 'patient'),
                    'suspicion': term_data.get('suspicion', 'confirmed'),
                    'antecedent': term_data.get('antecedent', 'current')
                }
                final_validated.append(entity)
        else:
            print(f"ðŸ” Validation sÃ©mantique hybride : {len(semantic_pairs)} paires Ã  analyser")
            
            # Validation sÃ©mantique hybride
            semantic_results = await self._validate_semantic_coherence_batch(semantic_pairs)
            
            # Application des rÃ©sultats de validation sÃ©mantique
            if semantic_pairs:
                print(f"ðŸ“Š Validation terminÃ©e : {len([r for r in semantic_results.values() if r['valid']])}/{len(semantic_pairs)} validÃ©es")
                
                # CrÃ©er un dictionnaire pour associer les paires Ã  leurs rÃ©sultats
                validation_results = {}
                for i, (original_term, snomed_term) in enumerate(semantic_pairs):
                    if i in semantic_results:
                        validation_results[(original_term.lower(), snomed_term.lower())] = semantic_results[i]
                
                # Application des rÃ©sultats
                final_validated = []
                rejected_terms = []
                
                for term_data in unique_terms.values():
                    original_term = term_data['term']
                    snomed_term = term_data['snomed_term']
                    pair_key = (original_term.lower(), snomed_term.lower())
                    
                    # VÃ©rifier si cette paire a Ã©tÃ© validÃ©e sÃ©mantiquement
                    if pair_key in validation_results:
                        semantic_result = validation_results[pair_key]
                        if semantic_result['valid']:
                            print(f"   âœ… ConservÃ© : {original_term} â†’ {snomed_term}")
                            current_snomed_term = snomed_term
                            # VÃ‰RIFICATION FINALE : Si le terme original est une correspondance exacte pour ce code,
                            # s'assurer que le snomed_term EST le terme original.
                            # Ceci est redondant si le flux de donnÃ©es est parfait, mais sert de garde-fou.
                            if self.validator.find_exact_term_code(original_term) == term_data['snomed_code']:
                                current_snomed_term = original_term
                                print(f"   ðŸ›¡ï¸ GARDE-FOU (Phase 5) : Pour {original_term} ({term_data['snomed_code']}), snomed_term forcÃ© Ã  '{current_snomed_term}'")
                            entity = {
                                'term': term_data['term'],
                                'snomed_code': term_data['snomed_code'],
                                'snomed_term': current_snomed_term,
                                'category': self._categorize_by_snomed_code(term_data['snomed_code']),
                                'negation': term_data.get('negation', 'positive'),
                                'family': term_data.get('family', 'patient'),
                                'suspicion': term_data.get('suspicion', 'confirmed'),
                                'antecedent': term_data.get('antecedent', 'current')
                            }
                            final_validated.append(entity)
                        else:
                            print(f"   âŒ RejetÃ© : {original_term} â†’ {snomed_term} ({semantic_result['reason']})")
                            rejected_terms.append({
                                'term': original_term,
                                'reason': semantic_result['reason']
                            })
                    else:
                        # Terme identique (pas besoin de validation sÃ©mantique) -> conservÃ© automatiquement
                        print(f"   âœ… Identique : {original_term} â†’ {snomed_term}")
                        current_snomed_term = snomed_term
                        # VÃ‰RIFICATION FINALE : Si le terme original est une correspondance exacte pour ce code,
                        # s'assurer que le snomed_term EST le terme original.
                        # Ceci est redondant si le flux de donnÃ©es est parfait, mais sert de garde-fou.
                        if self.validator.find_exact_term_code(original_term) == term_data['snomed_code']:
                            current_snomed_term = original_term
                            print(f"   ðŸ›¡ï¸ GARDE-FOU (Phase 5) : Pour {original_term} ({term_data['snomed_code']}), snomed_term forcÃ© Ã  '{current_snomed_term}'")
                        entity = {
                            'term': term_data['term'],
                            'snomed_code': term_data['snomed_code'],
                            'snomed_term': current_snomed_term,
                            'category': self._categorize_by_snomed_code(term_data['snomed_code']),
                            'negation': term_data.get('negation', 'positive'),
                            'family': term_data.get('family', 'patient'),
                            'suspicion': term_data.get('suspicion', 'confirmed'),
                            'antecedent': term_data.get('antecedent', 'current')
                        }
                        final_validated.append(entity)
            
            semantic_time = time.time() - semantic_start
            
            # === DÃ‰DUPLICATION FINALE PAR TERME ORIGINAL ===
            # Si mÃªme terme original avec codes diffÃ©rents â†’ garder le plus proche sÃ©mantiquement
            print(f"ðŸ”„ DÃ©duplication finale par terme original...")
            final_deduplicated = []
            seen_terms = {}
            
            for entity in final_validated:
                original_term = entity['term'].lower()
                snomed_term = entity['snomed_term'].lower()
                
                if original_term not in seen_terms:
                    # Premier terme de ce type
                    seen_terms[original_term] = entity
                    final_deduplicated.append(entity)
                else:
                    # Doublon dÃ©tectÃ© - choisir le meilleur
                    existing_entity = seen_terms[original_term]
                    existing_snomed = existing_entity['snomed_term'].lower()
                    
                    # PrioritÃ© : terme identique > terme diffÃ©rent
                    if original_term == snomed_term and original_term != existing_snomed:
                        # Le nouveau est identique, l'ancien non â†’ remplacer
                        print(f"   ðŸ”„ Remplacement: '{entity['term']}' â†’ '{entity['snomed_term']}' (identique) au lieu de â†’ '{existing_entity['snomed_term']}'")
                        final_deduplicated.remove(existing_entity)
                        final_deduplicated.append(entity)
                        seen_terms[original_term] = entity
                    elif original_term == existing_snomed and original_term != snomed_term:
                        # L'ancien est identique, le nouveau non â†’ garder l'ancien
                        print(f"   âœ… ConservÃ©: '{existing_entity['term']}' â†’ '{existing_entity['snomed_term']}' (identique) au lieu de â†’ '{entity['snomed_term']}'")
                    else:
                        # Cas ambigus â†’ garder le premier
                        print(f"   âš ï¸  Doublon gardÃ© premier: '{existing_entity['term']}' â†’ '{existing_entity['snomed_term']}' vs â†’ '{entity['snomed_term']}'")
            
            final_validated = final_deduplicated
            print(f"âœ¨ AprÃ¨s dÃ©duplication finale : {len(final_validated)} termes uniques")
            
            print(f"ðŸŽ¯ AprÃ¨s validation sÃ©mantique : {len(final_validated)}/{len(unique_terms)} termes conservÃ©s (â±ï¸ {semantic_time:.2f}s)")
            
            if rejected_terms:
                print(f"ðŸ—‘ï¸ RejetÃ©s pour incohÃ©rence sÃ©mantique : {len(rejected_terms)}")
                for rejected in rejected_terms:
                    print(f"   â€¢ {rejected['term']} : {rejected['reason']}")
        
        total_validation_time = time.time() - validation_phase_start
        print(f"âœ… Phase validation complÃ¨te terminÃ©e en â±ï¸ {total_validation_time:.2f}s")
        
        # === PHASE 5 : RÃ‰SULTATS FINAUX ===
        # CatÃ©gorisation des rÃ©sultats finaux
        final_findings = []
        final_procedures = []
        final_body_structures = []
        
        for term_data in final_validated:
            # DÃ©tection automatique de catÃ©gorie basÃ©e sur le code SNOMED
            category = self._categorize_by_snomed_code(term_data['snomed_code'])
            
            current_snomed_term = term_data['snomed_term']
            # VÃ‰RIFICATION FINALE : Si le terme original est une correspondance exacte pour ce code,
            # s'assurer que le snomed_term EST le terme original.
            if self.validator.find_exact_term_code(term_data['term']) == term_data['snomed_code']:
                current_snomed_term = term_data['term']
                print(f"   ðŸ›¡ï¸ GARDE-FOU (Phase 5) : Pour {term_data['term']} ({term_data['snomed_code']}), snomed_term forcÃ© Ã  '{current_snomed_term}'")

            entity = {
                'term': term_data['term'],
                'snomed_code': term_data['snomed_code'],
                'snomed_term': current_snomed_term,
                'category': category,
                'negation': term_data.get('negation', 'positive'),
                'family': term_data.get('family', 'patient'),
                'suspicion': term_data.get('suspicion', 'confirmed'),
                'antecedent': term_data.get('antecedent', 'current')
            }
            
            if 'finding' in category.lower() or 'disorder' in category.lower():
                final_findings.append(entity)
            elif 'procedure' in category.lower():
                final_procedures.append(entity)
            else:
                final_body_structures.append(entity)
        
        # Calcul des statistiques de performance
        max_individual = max([stats[1] for stats in extraction_stats]) if extraction_stats else 0
        fusion_gain = len(unique_terms) - max_individual
        semantic_filtered = len(unique_terms) - len(final_validated)
        total_time = time.time() - start_time
        
        # RÃ©sultat final avec temps dÃ©taillÃ©s
        result = {
            'entities': {
                'findings': final_findings,
                'procedures': final_procedures,
                'body_structures': final_body_structures
            },
            'statistics': {
                'extractions': extraction_stats,
                'before_fusion': max_individual,
                'after_fusion': len(unique_terms),
                'after_semantic': len(final_validated),
                'fusion_gain': fusion_gain,
                'semantic_filtered': semantic_filtered,
                'times': {
                    'parallel_extractions': parallel_time,
                    'individual_times': individual_times,
                    'sequential_equivalent': sum(individual_times),
                    'parallel_gain': sum(individual_times) - parallel_time,
                    'validation_phase': total_validation_time,
                    'fusion': fusion_time,
                    'semantic_validation': semantic_time,
                    'total': total_time
                }
            }
        }
        
        # Affichage des rÃ©sultats avec temps dÃ©taillÃ©s
        print(f"\nðŸŽ¯ RÃ‰SULTAT FINAL DE LA FUSION V2 :")
        print(f"   ðŸ” {len(final_findings)} constatations cliniques")
        print(f"   âš•ï¸  {len(final_procedures)} procÃ©dures/traitements")
        print(f"   ðŸ«€ {len(final_body_structures)} structures corporelles")
        print(f"   ðŸ“Š TOTAL : {len(final_validated)} entitÃ©s validÃ©es")
        
        print(f"\nðŸ“ˆ STATISTIQUES PAR EXTRACTION :")
        for extraction_num, valid_count, total_count in extraction_stats:
            percentage = (valid_count/total_count*100) if total_count > 0 else 0
            print(f"   Extraction {extraction_num} : {valid_count}/{total_count} ({percentage:.1f}%)")
        
        print(f"\nðŸš€ PERFORMANCE DE LA FUSION V2 :")
        print(f"   ðŸ“Š Avant fusion : max {max_individual} entitÃ©s validÃ©es")
        print(f"   âœ¨ AprÃ¨s fusion SNOMED : {len(unique_terms)} entitÃ©s uniques")
        print(f"   ðŸ§  AprÃ¨s validation sÃ©mantique : {len(final_validated)} entitÃ©s cohÃ©rentes")
        print(f"   ðŸ“ˆ GAIN fusion : +{fusion_gain} entitÃ©s supplÃ©mentaires")
        print(f"   ðŸ›¡ï¸ FILTRAGE sÃ©mantique : -{semantic_filtered} incohÃ©rences Ã©liminÃ©es")
        
        print(f"\nâ±ï¸ CHRONOMÃ‰TRAGE DÃ‰TAILLÃ‰ :")
        print(f"   ðŸš€ Extractions parallÃ¨les : {parallel_time:.2f}s")
        print(f"   ðŸ”„ Ã‰quivalent sÃ©quentiel : {sum(individual_times):.2f}s")
        print(f"   ðŸ’¨ Gain parallÃ©lisme : -{sum(individual_times) - parallel_time:.2f}s")
        print(f"   ðŸ” Phase validation : {total_validation_time:.2f}s")
        print(f"   ðŸ§  Validation sÃ©mantique : {semantic_time:.2f}s")
        print(f"   ðŸŽ¯ TEMPS TOTAL : {total_time:.2f}s")
        
        return result
    
    async def _validate_semantic_coherence_batch(self, term_pairs: list) -> dict:
        """
        Validation sÃ©mantique hybride groupÃ©e des correspondances SNOMED CT
        Combine filtrage mathÃ©matique rapide + LLM Gemini Flash pour les cas ambigus
        """
        from difflib import SequenceMatcher
        import time
        
        def calculate_math_score(gemini_term: str, official_term: str) -> float:
            """Score mathÃ©matique rapide combinant plusieurs mÃ©triques"""
            
            # 1. SimilaritÃ© Levenshtein
            levenshtein = SequenceMatcher(None, gemini_term.lower(), official_term.lower()).ratio()
            
            # 2. Mots en commun
            words_a = set(gemini_term.lower().split())
            words_b = set(official_term.lower().split())
            word_overlap = len(words_a.intersection(words_b)) / max(len(words_a), len(words_b)) if words_a or words_b else 0
            
            # 3. Contenance (un terme contient l'autre)
            a_clean = gemini_term.lower().strip()
            b_clean = official_term.lower().strip()
            contains = 1.0 if (a_clean in b_clean or b_clean in a_clean) else 0.0
            
            # Score global pondÃ©rÃ©
            return (levenshtein * 0.3 + word_overlap * 0.4 + contains * 0.3)
        
        def llm_validate_batch(llm_pairs: list) -> dict:
            """Validation LLM groupÃ©e pour les cas ambigus"""
            if not llm_pairs:
                return {}
            
            # Construire le prompt groupÃ©
            pairs_text = ""
            for i, (gemini_term, official_term) in enumerate(llm_pairs):
                pairs_text += f'{i+1}. "{gemini_term}" â†” "{official_term}"\n'
            
            prompt = f"""Tu es un expert mÃ©dical. Analyse si chaque paire de termes mÃ©dicaux dÃ©signe le MÃŠME concept clinique :

{pairs_text}

RÃ©ponds EXACTEMENT par ce format JSON :
{{
    "validations": [
        {{"paire": 1, "meme_concept": true}},
        {{"paire": 2, "meme_concept": false}},
        etc.
    ]
}}

RÃ¨gles :
- true = mÃªme concept clinique (identique ou Ã©quivalent)
- false = concepts cliniques diffÃ©rents"""

            try:
                start_time = time.time()
                response = self.model.generate_content(prompt)
                llm_duration = time.time() - start_time
                
                response_text = response.text.strip()
                
                # Parser la rÃ©ponse JSON groupÃ©e
                import json
                try:
                    # Extraire le JSON de la rÃ©ponse
                    json_start = response_text.find('{')
                    json_end = response_text.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = response_text[json_start:json_end]
                        result = json.loads(json_str)
                        
                        # Convertir en dictionnaire indexÃ©
                        batch_results = {}
                        validations = result.get("validations", [])
                        
                        for validation in validations:
                            paire_num = validation.get('paire')
                            meme_concept = validation.get('meme_concept')
                            
                            if paire_num is not None and meme_concept is not None:
                                paire_idx = paire_num - 1
                                if 0 <= paire_idx < len(llm_pairs):
                                    pair_dict = llm_pairs[paire_idx]
                                    if meme_concept:
                                        batch_results[paire_idx] = {
                                            "valid": True,
                                            "confidence": 1.0,
                                            "reason": "Concept identique",
                                            "duration": llm_duration / len(llm_pairs)
                                        }
                                    else:
                                        batch_results[paire_idx] = {
                                            "valid": False,
                                            "confidence": 0.0,
                                            "reason": "Concept diffÃ©rent",
                                            "duration": llm_duration / len(llm_pairs)
                                        }
                        
                        # ComplÃ©ter les paires manquantes
                        for i in range(len(llm_pairs)):
                            if i not in batch_results:
                                batch_results[i] = {
                                    "valid": False,
                                    "confidence": 0.0,
                                    "reason": "Paire non trouvÃ©e dans la rÃ©ponse",
                                    "duration": llm_duration / len(llm_pairs)
                                }
                        
                        return batch_results
                    else:
                        # Fallback en cas d'Ã©chec de parsing
                        return {i: {"valid": False, "confidence": 0.0, "reason": "Ã‰chec parsing JSON", "duration": llm_duration / len(llm_pairs)} for i in range(len(llm_pairs))}
                        
                except json.JSONDecodeError as e:
                    # Fallback simple en cas d'erreur JSON
                    return {i: {"valid": False, "confidence": 0.0, "reason": f"Erreur JSON: {str(e)}", "duration": llm_duration / len(llm_pairs)} for i in range(len(llm_pairs))}
                    
            except Exception as e:
                return {i: {"valid": False, "reason": f"Erreur LLM: {str(e)}", "confidence": 0.0, "duration": 0} for i in range(len(llm_pairs))}
        
        if not term_pairs:
            return {}
        
        # Phase 1 : Tri mathÃ©matique rapide
        math_results = []
        llm_cases = []
        llm_indices = []
        
        print(f"ðŸ” Validation sÃ©mantique hybride : {len(term_pairs)} paires Ã  analyser")
        
        for i, (gemini_term, official_term) in enumerate(term_pairs):
            math_score = calculate_math_score(gemini_term, official_term)
            
            if math_score >= 0.5:
                # Cas Ã©vident : ACCEPTER directement
                result = {
                    'valid': True,
                    'confidence': math_score,
                    'method': 'mathematical',
                    'reason': f"Score math Ã©levÃ© ({math_score:.3f})"
                }
                print(f"   âœ… Math: '{gemini_term}' â†’ '{official_term}' (score: {math_score:.3f})")
            elif math_score <= 0.01:
                # Cas trÃ¨s Ã©vident : REJETER directement
                result = {
                    'valid': False,
                    'confidence': math_score,
                    'method': 'mathematical', 
                    'reason': f"Score math trÃ¨s bas ({math_score:.3f})"
                }
                print(f"   âŒ Math: '{gemini_term}' â†’ '{official_term}' (score: {math_score:.3f})")
            else:
                # Cas ambigu : pour LLM
                result = {
                    'valid': False,  # Sera mis Ã  jour aprÃ¨s LLM
                    'confidence': 0.0,  # Sera mis Ã  jour aprÃ¨s LLM
                    'method': 'hybrid',
                    'reason': f"Score math ambigu ({math_score:.3f}) â†’ LLM"
                }
                llm_cases.append((gemini_term, official_term))
                llm_indices.append(i)
                print(f"   ðŸ¤– LLM: '{gemini_term}' â†’ '{official_term}' (score: {math_score:.3f})")
            
            math_results.append(result)
        
        # Phase 2 : Validation LLM groupÃ©e
        if llm_cases:
            print(f"ðŸ¤– Validation LLM groupÃ©e : {len(llm_cases)} paires ambiguÃ«s")
            
            start_llm = time.time()
            llm_batch_results = llm_validate_batch(llm_cases)
            total_llm_time = time.time() - start_llm
            
            print(f"âœ… LLM groupÃ© terminÃ© en {total_llm_time:.2f}s")
            
            # Mettre Ã  jour les rÃ©sultats avec les validations LLM
            for batch_idx, original_idx in enumerate(llm_indices):
                if batch_idx in llm_batch_results:
                    llm_result = llm_batch_results[batch_idx]
                    result = math_results[original_idx]
                    
                    result['valid'] = llm_result.get('valid', False)
                    result['confidence'] = llm_result.get('confidence', 0.0)
                    result['reason'] = llm_result.get('reason', 'Analyse LLM')
                    
                    status = "âœ…" if result['valid'] else "âŒ"
                    gemini_term, official_term = llm_cases[batch_idx]
                    print(f"   {status} LLM: '{gemini_term}' â†’ '{official_term}' (confiance: {result['confidence']:.2f})")
                    print(f"      â””â”€ {result['reason']}")
        
        # Convertir en dictionnaire indexÃ© pour le retour
        final_results = {}
        for i, result in enumerate(math_results):
            final_results[i] = result
        
        # Statistiques
        valid_count = sum(1 for r in math_results if r['valid'])
        math_count = sum(1 for r in math_results if r['method'] == 'mathematical')
        llm_count = len(llm_cases)
        
        print(f"ðŸ“Š Validation terminÃ©e : {valid_count}/{len(term_pairs)} validÃ©es")
        print(f"   ðŸ”¢ Math : {math_count}/{len(term_pairs)} ({math_count/len(term_pairs)*100:.1f}%)")
        print(f"   ðŸ¤– LLM : {llm_count}/{len(term_pairs)} ({llm_count/len(term_pairs)*100:.1f}%)")
        
        return final_results 

    def _categorize_by_snomed_code(self, snomed_code):
        """
        CatÃ©gorise automatiquement une entitÃ© basÃ©e sur son code SNOMED
        
        Args:
            snomed_code (str): Code SNOMED CT
            
        Returns:
            str: CatÃ©gorie dÃ©terminÃ©e
        """
        # RÃ¨gles de catÃ©gorisation basÃ©es sur les hiÃ©rarchies SNOMED
        # Ces codes correspondent aux grandes hiÃ©rarchies SNOMED CT
        
        # Findings/Disorders (domaine clinique)
        if snomed_code.startswith(('271', '40', '38', '41', '27', '36', '23', '25', '42')):
            return "Clinical finding"
        
        # Procedures (interventions)  
        elif snomed_code.startswith(('71', '77', '23', '18', '38', '89', '17', '18')):
            return "Procedure"
            
        # Body structures (anatomie)
        elif snomed_code.startswith(('51', '81', '15', '79', '24', '36', '12', '91')):
            return "Body structure"
            
        # Observable entity (observations)
        elif snomed_code.startswith(('36', '24', '25')):
            return "Observable entity"
            
        # Substances (mÃ©dicaments, substances)
        elif snomed_code.startswith(('44', '37', '39', '41')):
            return "Substance"
            
        # Par dÃ©faut, catÃ©goriser comme finding
        else:
            return "Clinical finding"
    
    def _security_check(self):
        """VÃ©rification de sÃ©curitÃ© des limites API"""
        can_proceed, message = security_manager.can_make_request()
        if not can_proceed:
            print(f"ðŸš« EXTRACTION BLOQUÃ‰E : {message}")
            return False
        return True
    
    def extract_medical_entities(self, text, use_context_modifiers=True):
        """
        Extraction d'entitÃ©s mÃ©dicales Ã  partir de texte brut
        Compatible avec la mÃ©thode V2 asynchrone
        """
        try:
            # CrÃ©er un objet MedicalNote temporaire
            medical_note = MedicalNote(
                patient_id="TEMP_001",
                patient_name="Patient Temporaire",
                date="2025-01-01",
                doctor="Dr. Extracteur",
                content=text,
                specialty="Extraction automatique"
            )
            
            # Utiliser la mÃ©thode d'extraction existante
            extraction = self.extract_snomed_info(medical_note)
            
            # Convertir au format attendu par la mÃ©thode V2
            findings = []
            procedures = []
            body_structures = []
            
            for finding in extraction.clinical_findings:
                findings.append({
                    'term': finding.term,
                    'snomed_code': finding.snomed_code,
                    'category': 'clinical_finding',
                    # RÃ©cupÃ©rer TOUS les modifieurs contextuels
                    'negation': getattr(finding, 'negation', 'positive'),
                    'family': getattr(finding, 'family', 'patient'),
                    'suspicion': getattr(finding, 'suspicion', 'confirmed'),
                    'antecedent': getattr(finding, 'antecedent', 'current')
                })
            
            for procedure in extraction.procedures:
                procedures.append({
                    'term': procedure.term,
                    'snomed_code': procedure.snomed_code,
                    'category': 'procedure',
                    # RÃ©cupÃ©rer TOUS les modifieurs contextuels
                    'negation': getattr(procedure, 'negation', 'positive'),
                    'family': getattr(procedure, 'family', 'patient'),
                    'suspicion': getattr(procedure, 'suspicion', 'confirmed'),
                    'antecedent': getattr(procedure, 'antecedent', 'current')
                })
            
            for structure in extraction.body_structures:
                body_structures.append({
                    'term': structure.term,
                    'snomed_code': structure.snomed_code,
                    'category': 'body_structure',
                    # RÃ©cupÃ©rer TOUS les modifieurs contextuels
                    'negation': getattr(structure, 'negation', 'positive'),
                    'family': getattr(structure, 'family', 'patient'),
                    'suspicion': getattr(structure, 'suspicion', 'confirmed'),
                    'antecedent': getattr(structure, 'antecedent', 'current')
                })
            
            return {
                'entities': {
                    'findings': findings,
                    'procedures': procedures,
                    'body_structures': body_structures
                }
            }
            
        except Exception as e:
            print(f"âŒ Erreur extraction_medical_entities: {str(e)}")
            return None 